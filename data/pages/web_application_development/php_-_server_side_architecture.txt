====== PHP - Server Side Architecture ======

PHP is a server side scripting language. It is a dynamic and interpreted language. PHP is not compiled. It runs through an interpreter, which is usually a PHP processor module that is integrated into a web server. For our purposes, that would be the Apache HTTP server which includes ''mod_php'' as the processor module. PHP can also be ran as CGI, but that is not as common as the ''mod_php'' method. It started out being an embedded scripting language to HTML, but grew into a full fledged programming language. It includes its own command line interface and can run as a stand alone server (but only used for development). It is single threaded and share nothing, meaning that it doesn't natively support concurrent processing and it doesn't share data between processes. PHP is currently the most widely used web programming language powering Wikipedia, Facebook, Digg and more. 

While going through this article, try using [[http://phpbounce.aws.af.cm|PHPBounce]] to quickly test out your code if you don't have a chance to run a web server.

===== Object Oriented Programming (OOP) =====

There four fundamental [[wp>Programming paradigm|programming paradigms]]. They are object-oriented, imperative, functional and logic programming. PHP can support multiple paradigms, namely procedural (imperative) and object oriented. It incorporates aspects of functional, but developers don't architect their PHP applications in a functional way. The most common programming paradigm for PHP is object oriented.

Object oriented simply means that we try to separate our programming into logical units of code. Each unit of code is an object. Each object can have multiple data properties that describe the object and multiple functions called methods. When we normally start programming, we naturally start in a procedural manner, specifying a list of tasks and subroutines before getting an end result. However in OOP, each object is an independent unit of code capable of receiving input, processing data and returning output. Each object can call on other objects, be dependent on external objects, or extended from parent objects. Each object has a distinct role. The decision of how granular we want when separating code into objects depends on the complexity of the unit of code. If you can find yourself doing multiple different //types// of tasks in one subroutine, then it's probably time to separate each //type// of functionality into different objects or different object methods. Objects should be created with one single responsibility, one way to check if an object is doing too many things is checking how many ''if'' or ''switch'' statements that are used to branch off logic. This is called the [[wp>Single responsibility principle|Single Responsibility Principle]]

In order to create objects, we actually first specify a class. Classes are blueprints for objects. Objects are actually //instances// of classes. So a single class can be used to create multiple objects. Note that the words objects and classes are used interchangeably. However when people say class it usually refers to the creation of the class, whereas when people refer to object, it usually refers to instantiated context of the class.

It's important to note that by convention we name our classes with capitalised first letters and the rest [[wp>CamelCase|camel cased]]. Except when we're naming interfaces or abstracts. Furthermore we put each class into its own single file, so there's never two classes in one file. The file name should also match the name of the class including the capitalisations. This file naming convention however is not applied when we're using models, views or controllers in Codeigniter. The reason for this is due to a mismatch of conventions between the PSR autoloading standards and Codeigniter.

<code php>
//a class of Elephant, classes are usually capitalised
class Elephant{}

//$elephant is an object instance of the Elephant class
$elephant = new Elephant;
</code>

OOP has four main concepts: encapsulation, abstraction, inheritance and polymorphism. 

==== Encapsulation ====

OOP arose from the need to modularise and separate the functionality of software as software grew in complexity. The OOP approach encourages encapsulation which means we should place units of data inside objects which can only be accessed and manipulated through the object's methods. The methods act as intermediaries between different objects. You should never access data properties from the object directly.

The motivation for encapsulation is discipline and abstraction. By encapsulating the data properties and thus the state of the object, we're hiding the implementation details of the object, but instead providing an method API that external objects can access. This helps with the abstraction process by providing a consistent way of accessing objects. This discipline is also useful when software development takes place in teams.

Furthermore since the data properties are hidden, and only the names of methods are accessible, we can change the implementation details of the object without worrying of breaking the API for other objects.

<code php>
class Elephant{

    //encapsulated private data property of $_colour. The private makes it only accessible within the object's instance using $this. This underscore is only a convention of prefixing private or protected variables.
    private $_colour;
    
    //public accessor method that sets the $_colour and echos it
    public function set_colour($colour){
        
        $this->_colour = $colour;
        echo $colour;
        
        //did you know that we can dynamically create object instance variables too? This only gets created when set_colour is called from the instance
        $this->hue = $colour;
        
    }
  
}

$red_elephant = new Elephant;
//we can access the public method that acts as the intermediary to the private data property
$red_elephant->set_colour('red');

//second object instantiation
$green_elephant = new Elephant;
$green_elephant->set_colour('green');
echo $green_elephant->hue;
</code>
==== Abstraction ====

Encapsulation is actually technique of a more generic concept called abstraction. Objects should be abstracted. This means that the concrete implementation details should be hidden and abstracted away, so that only contextually important methods are available at a particular perspective. Here's a couple examples: the concept of a "List" is an abstraction of "Fruit List" or "Car List". The concept of a "Living Thing" is an abstraction of "Animals" which is an abstraction of "Dog". The concept of "People" is an abstraction of the person "Roger" and "Matthew". When constructing an object, the available object properties should be relevant to the context of which it is used. All "People" may have heights and weights, but only "Roger" has a preference for "Action Movies" and only "Matthew" has a tattoo saying "I'm Awesome". So when I'm defining the "People" object, it should not have properties of movie preferences or tattoos, those are not contextually relevant to how I would perceive or represent "People" as an abstract concept.

Abstraction is achieved by encapsulating concrete implementation details, but it can also be achieved by leaving concrete implementation details later to extend the abstract class as the parent class.
==== Inheritance ====

Inheritance can be used to establish an abstract hierarchy of concepts and objects. At the same time because we're not rewriting the parent class's code, we enhance code reuse. Essentially child classes can inherit from parent classes, so that it inherits its parent's properties and methods.

Methods specified in the parent classes can be overwritten by child classes unless finalised with ''final //scope// function //name//{}''. PHP also does not support multiple inheritance, so a child can only inherit from one parent. However there are different strategies to overcome this. Classes can also chain inheritance.

<code php>
class Animal{

    //private scoped variables will not be accessible in the child classes
    private $_exists = true;
    
    //protected scoped variables are accessible in the child class but not outside of the class
    protected $_breathing_noise = 'breathing';
    
    public function breathe(){
        echo $this->_breathing_noise;
    }
    
}

//Elephant is a child of the abstract parent Animal class
class Elephant extends Animal{
    
    private $_colour;
    
    public function set_colour($colour){
        //$this can access this class and the parent's class when the object is instantiated
        $this->_colour = $colour;
        echo $colour;
    }
    
    public function set_breathing($noise){
        $this->_breathing_noise = $noise;
    }
    
}
     
$elephant = new Elephant;
$elephant->set_colour('red');
$elephant->set_breathing('HRRUMPH!');
$elephant->breathe(); //look accessing the parent's method!
</code>

==== Polymorphism ====

Simply put polymorphism is simply that classes can have different functionality and yet share the same interface. Essentially you would be able to call a method that has a name, that is shared by classes which occupy the same abstraction level, but have different functionality. The point is so that you can write less code by not having to specify ''if'' statements to switch functionality based on some context. This also means when you're working in teams you can establish a standard for API methods for similar classes.

An example would be a button. Everybody knows how to interact with a button. You either press it or you don't. But what the button does, who knows? So all buttons should have the same interface, such as a method called ''press''.

Polymorphism is supported by two extra constructs: Interfaces and Abstracts.

=== Interfaces ===

Interfaces are contracts that objects implement. An object can implement multiple interfaces. An interface is simply an empty class with named methods, but no implementation details inside the methods. Any class that implements an interface will have to create concrete methods that match the empty methods in the interface, it they don't, it will cause a fatal error. By using interfaces you're guaranteeing that your implemented objects will have a set of public API methods.

Interfaces support polymorphism because different objects can implement the same interface. If we take the button example, there could be a button interface, which red button and green button implements.

<code php>
//We usually prefix our interfaces with i, and class names are usually camelcased
interface iButton{
    
    public function press();
    
    public function change_colour();
    
}

class RedButton implements iButton{

    public function press(){
        echo 'Alert! RED BUTTON PRESSED!';
    }
    
    public function change_colour(){
        echo 'Flash RED and ORANGE!';
    }

}

class GreenButton implements iButton{

    public function press(){
        echo 'Warning! GREEN BUTTON PRESSED!';
    }
    
    public function change_colour(){
        echo 'Flash GREEN and BROWN!';
    }

}

//now we can expect the same API methods, and hence polymorphic method! Same name, different functionality.
$red = new RedButton;
$red->press();
$green = new GreenButton;
$green->press();
</code>

Interfaces can also include constants which are accessible statically in their implementing objects. See the [[#using_libraries|Using Libraries]] section for more on static classes. Interfaces can also be extended, this allows interfaces to occupy multiple levels of abstraction. You can have a ''interface iLivingThing'' which is an abstraction of ''interface iAnimal''.

Interfaces are most commonly used with type hints to enforce type checking when injecting dependencies. See [[PHP - Design Patterns]] for more information on dependency injection.

<code php>
interface iAdd{

    //interfaces can also demand parameters
    public function add($one, $two);

}

class Calculator implements iAdd{

    public function add($one, $two){
        $result = $one + $two;
        return $result;
    }

}


class Calculation{

    //the iAdd type hint here forces the $calculator to be any object that implements the iAdd interface, because Calculation is expecting the add method which is guaranteed by the iAdd interface
    //__construct methods are called as soon as the class is instantiated, its parameters dictate parameters that are passed during object instantiation
    public function __construct(iAdd $calculator, $one, $two){
        $result = $calculator->add($one, $two);
        echo $result;
    }
    
}

//if I passed in an object that didn't implement the iAdd interface, the typehint would cause a fatal error
//you may notice that this object instantiation has parentheses "()", these are used when there is a __construct method, which is called as soon as the object is instantiated
$calculation = new Calculation(new Calculator, 5, 6);
</code>

The practice of using interfaces with type hinting and dependency injection is important, as it modularises the dependencies of classes. The Calculation class depends on an object that implements the iAdd interface. It doesn't care what the passed in object is, as long as it has the methods specified in the interface, because it's expecting to use those methods. Therefore, this also loosens the dependency coupling, allowing us to swap out the Calculator object with a different object with different implementation details as long as it preserves the polymorphic method names and expected output.

This practice is quite useful when you need to abstract the API (the way you use something) away from the concrete implementation (what the something is). One example would be if you're using a class that needs to store data into a database. That class should not care what kind of database it is, and how it stores its data as long as it has access to a set of predictable API methods. If you hard coded the database dependency and decided to change the database some time later, then you would have to change all the method calls, which is not good for maintenance. By using an interface, you avoid all of that by simply swapping out the database class and implementing the interface. Of course this only works if you abide by type hinting and dependency injection.

Note that objects can implement multiple interfaces, this just makes the instantiation of the object more strict, in that they have to implement all the methods specified in the interfaces.

=== Abstracts ===

Abstracts are interfaces that allow concrete implementations of their methods, however classes extend abstracts instead of implementing them, this means only one abstract can be used for each object. You might then think why can't we just use a normal class and have children that extend it. Well you could, but in programming, it's good to be explicit. Think of abstracts as a strict possessive parent class that must have children, and then forces its children to do things their way. But at the same time, it provides shared methods to their children to use. Hence abstracts are never used by themselves.

Developers use abstracts to provide a boilerplate classes. Abstract methods which are the ones that children are forced to implement have to be either scoped at protected or public. Private wouldn't work.

<code php>
//abstracts are classes, that's why we still have a class operator, furthermore we prefix abstracts with a little a
abstract class aArmor{

    //shared variable
    //variables or properties cannot be abstracted, they are considered concrete implementation details
    protected $_weight;
    
    //shared method
    public function set_weight($kg){
        $this->_weight = $kg;
    }
    
    //this is what will have to be implemented by the children
    abstract public function armor_rating();
    
}

class ChineseArmor extends aArmor{

    public function __construct($weight){
        $this->set_weight($weight);
    }
    
    
    //implemented functions have to be at the same or less restrictive scoping, public is the least restrictive!
    public function armor_rating(){
        echo 'Over 10,000!';
    }
    
    public function get_weight(){
        echo $this->_weight;
    }

}

$armor = new ChineseArmor('100 Kg');
$armor->armor_rating();
$armor->get_weight();
</code>

Abstracts can also be type hinted, in fact all objects can be type hinted, so you can use them in the same way as interfaces with dependency injection.

Abstracts can also be used with interfaces.

<code php>
interface iPhysicalObject{

    //abstracts do not need to implement this, only the final concrete child class
    public function weight();

}

abstract class aArmor implements iPhysicalObject{

    //shared function
    public function armor_rating(){
        //abstracts can reference weight method even though it doesn't exist yet, because it has been guranteed by the interface
        $rating = 10 * $this->weight();
        return $rating;
    }
    
    abstract public function blacksmith();

}


class ChineseArmor extends aArmor{

    //defined by interface
    public function weight(){
        return 100;
    }
    
    //defined by abstract
    public function blacksmith(){
        echo 'The Yellow Dragon!';
    }
    
    public function protection(){
        $protection = $this->armor_rating();
        //if the armor was created by the The Yellow Dragon! we add a bonus of 1000
        if($this->blacksmith() == 'The Yellow Dragon!'){
            $protection + 1000;
        }
        return $protection;
    }

}


class Fight{

    public function __construct(aArmor $armor){
        if($armor->protection() > 100){
            echo 'You won!';
        }
    }

}

$battle = new Fight(new ChineseArmor);
</code>
===== Model View Controller (MVC) =====

The model view controller pattern is an architecture pattern that separates software applications into three areas. The model is the business logic and application data. The view is the presentational user interface of the data. The controller is what binds the model's data to the view inputs, and it also routs user input requests to the appropriate interactions. The central ideas of the MVC pattern is [[wp>Code reuse|code re-usability]], [[wp>Separation of concerns|separation of concerns]] and [[http://www.slideshare.net/damiansromek/thin-controllers-fat-models-proper-code-structure-for-mvc|thin controllers - fat models]].

MVC architecture is usually placed behind a [[wp>Front Controller pattern|front controller]]. These front controllers essentially establish the workflow and middleware for every request and response. The front controller may include a router, or the router may be part of the middleware. The router routs requests to the appropriate controller which then calls upon its models and views to produce a response.

Codeigniter is an MVC framework. The code you write is separated into models, views and controllers. We also further separate our code into libraries, packages and helpers, but that's for later. Codeigniter also includes a front controller which is the index.php at your project root. Codeigniter automatically routs requests in the URL to the controller with a matching name, however this can be customised in the routes.php. The Apache HTTP server actually sends all requests to the index.php, the index.php then calls upon the rest of the architecture and produces a response. No other files in Codeigniter is accessed directly. This gives an easy way to hook into the request and response flow and introduce middleware.

Note that there is a many to many relationship between models, controllers and views. One controller may call upon multiple models and multiple views. Models don't call controllers or views, and views don't call controllers or models. They simply return data to the controller that called them. Therefore models and views can have multiple controllers that interact with them.

Interfaces, abstracts and further inheritance can be applied to Codeigniter's models, views and controllers. However this practice is uncommon. I recommend you to use only these features in libraries or packages, and follow Codeigniter extension suggestions in their userguide if you need customised functionality in the architecture.

{{ :web_application_development:appflowchart.gif |}}

==== Model ====

Your models is where your business logic and application data resides. Your models should contain the bulk of your operations and processing. Models also contain accessors and mutators to your database if any. It's important to understand that models aren't just for storing state, but also the operations on the behaviour of your system. If you were writing a Chess game, not only would the storage of the chess board state be via the model, but also the rule checking algorithms and artificial intelligence. Once this business logic finds itself needed in other areas, that's when you abstract it into its own package or library. That way it can be called and executed in multiple models.

Models return processed data to the controller. Models don't need to know where it gets called, just that it does.

Models can also perform data validation, but data validation that involves simply input filtering for security purposes should be left to the controller, because that's metaphorically the gate to your software fortress. However if the data validation requires business logic to be performed, such as checks against the database, then the it should be placed in the model. However opinions may vary on this suggestion.

Example Codeigniter Model:

<code php>
//by convention we suffix the model with _model and all models extend the CI_Model from Codeigniter
class Blog_model extends CI_Model {

    public function __construct(){
        //when the model gets loaded into the controller, it calls the parent __construct method. This __construct method is actually from CI_Model. This way when we instantiate this object, we also instantiate the parent.
        
        //CI_Model's __construct() is not implicitly called because we method overrided it with this child class's __construct. Therefore in order to setup the parent's class, we need to call it with parent::__construct(). If this model did not have __construct, then the parent's __construct would be automatically called.
        parent::__construct();
        
        //here is where you load any dependencies as well, either through CI's loader or through autoloading
        
    }
    
    //more accessors and mutators here...

}
</code>

=== CRUD ===

CRUD refers to [[wp>Create, read, update and delete|Create Read Update and Delete]]. These are the four basic functions of any model when interacting with a database. You should read the [[#database|Database Section]] before proceeding. If you're using models to interface with a database, the convention is to name your model after the table name you're using. In each model class, there will be four public methods corresponding to CRUD.

<file php user_model.php>

class User_model extends CI_Model{

    public function __construct(){
        parent::__construct();
        //this will become available as $this->db..etc
        $this->load->database();
    
    }
    
    //you can name these functions using other terms or even terms closer to HTTP if you prefer
    
    //the parameters here would be passed in from the controller, they would be acquired from the input library
    //we could have as separate parameters, or a single array object
    public function create($username, $password, $email){
        
        $data = array(
            'username' => $username, //perhaps make it lowercase?
            'password' => password_hash($password), //password_hash is not a defined function anywhere yet, I'm setting here so you remember that passwords need to be hashed and salted before inputting it into the database. See the security section on passwords. THIS IS IMPORTANT!
            'email'    => $email,
        );
        
        $query = $this->db->insert('user', $data); 
        
        if(!$query){
        
            //some error occurred? We should log the database error
            //the below only works if $db['default']['db_debug'] = FALSE in the database configuration (so that it doesn't display straight to the user
            
            $msg = $this->db->_error_message();
            $num = $this->db->_error_number();
            $last_query = $this->db->last_query();
            
            log_message('error', 'Problem Inserting to user table: ' . $msg . ' (' . $num . '), using this query: "' . $last_query . '"'); 
            
            return false;
            
        }
        
        //it worked! return the last insert_id!
        return $this->db->insert_id();
    
    }
    
    public function read($id){
    
        //first validate the $id somehow
        if(!is_numeric($id)){
            show_404();
        }
        
        //we can just use *, but this is required when specifying multiple tables
        $this->db->select('user.*');
        $this->db->where('user.id', $id);
        $this->db->from('user');
        
        $user_query = $this->db->get();
        
        if($user_query->num_rows() > 0){
        
            $result = $user_query->row();
            
            return $result;
        
        }else{
        
            //this is probably not an error, most likely there was no user with that id, so there were no results
            return false;
        
        }
    
    }
    
    //this would assume that the data array has already been passed in
    //if there are columns you don't want to update, just don't pass them in as key to value properties of the $data array
    public function update($id, $data){
    
        $this->db->where('id', $id);
        $this->db->update('user', $data);
        
        if($this->db->affected_rows() > 0){
            //this returns the number of affected rows
            return $this->db->affected_rows();
        }
        
        //we're not doing any error logging here, you can implement it yourself, remember this could actually mean there were no users with that id, not a database error
        return false;
    
    }
    
    public function delete($id){
    
        $this->db->where('id', $id);
        $result = $this->db->delete('user');
        
        //db->delete would return true if it worked
        if($result){
            //we can return the number of rows deleted
            return $this->db->affected_rows();
        }else{
            return false; //couldn't delete
        }
    
    }
    
    //the above are not the only methods you would have, but are just the bare minimum, perhaps you need a method that gets all the listings, not just one entry...

}

</file>

You may notice eventually that CRUD is simply one of the many configurations of these four operations at different abstraction levels

|         ^ SQL             ^ HTTP (RESTful)     ^
^ Create  | INSERT          | POST               |
^ Read    | SELECT          | GET                |
^ Update  | UPDATE          | PUT                |
^ Delete  | DELETE          | DELETE             |
==== View ====

Your view is where your user interface code lies. Remember that HTML and CSS markup you did while in the Web Design section? Well that HTML markup is going to be cutup into independent layouts in the view. The CSS, Javascript and other assets actually remain where they are. The view is also where we implement [[#templating|templating]], which is the practice of modularising user interfaces into reusable components so they can be swapped in and out with other user interface elements. In order to pull in dynamic data, we actually place variables inside the views which will be injected from the controller after the controller has the data from the model.

By convention we suffix views files with _view. So any file names would like ''home_view.php''.

Example Codeigniter View with embedded PHP:

<code php>
<html>
    <head>
        <title>Example Page!</title>
    </head>
    <body>
        <p>Hello! <? echo 'World!'; ?></p>
    </body>
</html>
</code>
==== Controller ====

The controller is the manager of the model and view. In Codeigniter the name of the controller corresponds to the first URL segment. The second URL segment is executed as a corresponding method. Any further URL segments are passed to the methods as parameters. Controllers are meant to be thin and simply call upon models and pass in parameters, afterwards it binds the returned data to the view and at the same time responds back to the client with the finished data. The only business logic that controllers should have is any input filtering, HTTP routing tasks, and view binding.

Example Codeigniter Controller:

<code php>
//This Home class corresponds to home.php as a filename, home then becomes the first URL segment as http://example.com/index.php/home or http://example.com/home (if using URL rewriting via Apache .htaccess)
class Home extends CI_Controller {

    //you can build up your view binding by creating a privately scoped member array, when you're ready to build up the view, just append values onto this array and pass this to the view. By creating this independent from any methods, the view data is then abstracted and can be added to from multiple methods
    private $_view_data = array();

    //since it is a class that extends the CI_Controller, we still have a __construct that is called as soon as it is initiated
    public function __construct(){
    
        parent::__construct();
        
        //load commonly used dependencies using CI, you would not dependency inject using controllers, because you don't control the calling of controllers
    
    }
    
    //this is the actual method that would be called if there was no second URL segment, it can also be explicitly called by http://example.com/home/index
    //to be callable by URL, they would have to be scoped at public
    public function index(){
    
        //load models and do processing
        //load views and return the response
        $this->load->view('home_view', $this->_view_data);
    
    }
    
    //you can access this via http://example.com/about/2, the 2 becomes the id
    public function about($id){
    
    }
	
}
</code>

When processing form inputs, instead of [[http://ellislab.com/codeigniter/user-guide/libraries/form_validation.html|placing all the validation rules in your controller's methods]], keep them in a separate configuration file. Refer to this tutorial on [[http://chris-schmitz.com/cleaning-up-your-codeigniter-controllers/|Cleaning up your Codeigniter Controllers]] to see how to do this:

There'll be many developers who argue that your form inputs should be validated in your model. However Codeigniter's form validation library doesn't work from the model, so we have to place in our controller. But by following the technique of placing form rules in an external config file, this makes form validation much easier and thinner in our controllers.
===== Templating =====

Templating is the process of using layouts and partials to form complete view user interfaces. In following the separation of concerns, templates should contain as little business logic as possible. It's only there to bring together user interface elements and have dynamic data inserted into them. The problem comes when we want to have reusable partial templates and shared layout templates.

Think of layouts as a template file that specifies the header, footer, sidebar and any other elements that are shared across web pages and hardly change. A large web application may have multiple layouts, one for the blog, one for the administration panel, one for the home page. Each of which may have different headers or lack/include a sidebar. Layouts are the master templates, the templates that specifies other templates.

Think of partials as reusable templates across many different areas. An example would be a table row that may get used in different tables in different pages in different layouts. Partials are the grand children templates, templates that don't specify any other template and doesn't know which parent will pick it up to use it.

There are a number of templating libraries for PHP, some of them catered towards Codeigniter, and others are for generic use. Many of them provide their own domain specific language. You can choose to go with third party solutions, however I like to roll my own simpler solution. PHP after all was a templating language.

So I present to you the static helper class CiTemplating:

  * [[https://github.com/Polycademy/CiTemplating|CiTemplating]]

You can install it via composer (follow the instructions on the README) and it will be autoloaded, allowing you to call it like a global function without the need of instantiating it or using namespaces. Namespaces couldn't be used, due to the nature of templating, it would require an ''use'' namespace import, which would go against the concept of minimal logic views. Please see the section on [[#autoloading|Autoloading]] to find how to integrate autoloading magic into Codeigniter.

To use this library we need to establish some conventions:

  * Each controller you have should have a corresponding folder with a matching name in the view folder. Therefore a controller named ''blog.php'' should have the folder ''views/blog''.
  * Each public method in a controller should have their own view with a matching name stored in their view controller folder. Therefore the controller ''blog.php'' with ''articles'' as a public method should have the view ''views/blog/articles_view.php''.
  * Partials are appended with ''_partial'', and are stored in the partials folder such as ''views/partials/rows_partial.php''.
  * Layouts are appended with ''_layouts'', and are stored in the layouts folder such as ''views/layouts/main_layout.php''.

Your views directory can start to look like this:

  views
    |
    |----layouts
    |       |
    |       |----default_layout.php
    |       |----json_layout.php
    |
    |----partials
    |       |
    |       |----rows_partial.php
    |
    |----home
    |       |
    |       |----index_view.php
    |
    |----blog
            |
            |----articles_view.php
==== Layouts ====

The CiTemplate static class provide a static ''compose'' method allowing you to define both views and their corresponding layouts. All layouts should inject a ''$yield'' variable. When you run ''Template::compose()'', it will first sent any view data to the specified view, and return the compiled template, before dynamically adding it to the view data array and injecting it into the layout. For example, you should have a ''default_layout.php'' that is like this

<file php default_layout.php>
<? Template::partial('header', $header) ?>
<?= $yield ?>
<? Template::partial('footer', $footer) ?>
</file>

The corresponding call to this layout would be something like, if it was called inside the ''index()'' method of a controller..

<code php>
$view_data = array(
    'header' => array(),
    'footer' => array(),
    'data' => 'data_value',
    //... etc
);
Template::compose('index', $view_data);
</code>

The ''$view_data['header']'' and ''$view_data['footer']'' would be be injected into the partial parameters of ''$header'' and ''$footer'' in the layout. The rest of the properties in the view data array would be passed into the ''index_view.php'', and the returned output would automatically be injected into the $yield. This obviously means you should not use have a property key of ''$view_data['yield']'' when defining your view data array, as it would get overwritten.

The compose method also has a third parameter that specifies the layout file to use. By default it is ''default''. The compose method allows you to use full names such as ''Template::compose('index_view', $view_data, 'default_layout');'', but it isn't necessary as it will automatically append ''_view'' or ''_layout'' to the end of the parameter if it doesn't have it. The same goes with partials.

A cool thing you can do with this method is to specify a JSON layout like so:

<file php json_layout.php>
<?php

header('Content-type: application/json');

echo json_encode($yield, JSON_NUMERIC_CHECK | JSON_FORCE_OBJECT);
</file>

You would call this via:

<code php>
//we pass false into the view, because don't need one to pass in straight json_data, json_data has to be an array too!
Template::compose(false, $json_data, 'json');
</code>

To understand how the compose method works, look into the source code of ''Template.php''. It's well documented.
==== Partials ====

Partials allow you define and call in reusable templates within templates. They also allow you to loop through results and repeat a compiled template with minimal logic. Partials are stored in the partials folder. Although it is possible to modify the code to allow partials anywhere in the view directory, I found it more appropriate and simpler to specify that all of them must be in one directory. Do note that it is possible to specify subdirectories in the partials folder though.

Partials are called within template views like so:

<code php>
//first parameter is the name of the partial with or without '_partial' appended to it, second parameter is the variable to pass in
Template::partial('header', $header);
</code>

To loop through results you would need to pass ''true'' to the third parameter in your view file.

<code php>
Template::partial('row', $row_data, true);
</code>

This would call in a partial and attempt the iterate through //values// of the ''$row_data''. The values are by default specified in the partial as ''$row'' variables. It is important to understand this. When you call ''Template::compose()'' to a view that has a looped partial, the view data array you pass in should have a property of which its key name matches the injected parameter of ''Template::partial''. This property needs to also be an array, and its values are what is iterated over and stored in a ''$row'' variable. The partial can simply call ''$row'' if it's a scalar value, but if you need multiple properties in the ''$row'' variable, then the values that are iterated should also be an array.

Imagine you had a controller code like this:

<code php>
$view_data = array(
    'row_data' => array(
        'First Row',
        'Second Row',
        'Third Row',
    ),
);

Template::compose('table', $view_data);    
</code>

Then the view could be:

<code php>
<table>
    <tbody>
        <? Template::partial('row', $row_data, true) ?>
    </tbody>
</table>
</code>

Then the partial would be:

<code php>
<tr>
    <td><?= $row ?></td>
</tr>
</code>

Each of the ''$row'' would contain the scalar string of "First Row", then "Second Row", and finally "Third Row".

If I wanted the ''$row'' to have multiple parameters, then I would change ''$row_data'' to be an array of arrays.

<code php>
$view_data = array(
    'row_data' => array(
        array(
            'name' => 'Roger',
            'id' => '4'
        ),
        array(
            'name' => 'Dave',
            'id' => '5'
        ),
    ),
);

Template::compose('table', $view_data);

//and this would be in the partial

<tr>
    <td><?= $row['name'] ?></td>
    <td><?= $row['id'] ?></td>
</tr>
</code>

As you can see array keys don't matter here.

By default they automatically echo their data as soon as they are called. However you can also specify that they return data as a variable by setting the fourth buffer parameter to true.

<code php>
$partial_compiled = Template::partial('row', $data, false, true);
</code>
===== Using Libraries =====

One the key concepts of OOP is reusing code. Libraries are the primary way of reusing and sharing code. Whereas code in the MVC refers to a specific implementation of a particular web application. Libraries are created independently of what the web application does. Libraries can be a list of procedural functions, however these are usually called helper functions, and since we're using OOP, we should avoid using function lists which are hard to test, maintain, extend and impossible to autoload. Therefore our libraries will either be normal classes, abstract classes, interfaces or static classes.

There are different ways of structuring library classes, most of the ways are dependent on how best to autoload or not autoload the classes, and the usage or non-usage of namespacing. The PSR-0 (composer) standard was all about standardising sharable code libraries that could be autoloaded. However there are a number of other ways including Codeigniter's native library loading functionality, Codeigniter Sparks package management and of course rolling our own autoloading. This section will go through each and also discuss static classes.
==== Codeigniter Libraries ====

Codeigniter allows you to create your own libraries and store them in the ''application/libraries'' folder. Follow the user guide on [[http://ellislab.com/codeigniter/user-guide/general/libraries.html|loading libraries]] and [[http://ellislab.com/codeigniter/user-guide/general/creating_libraries.html|creating libraries]] for more information. For the purposes of autoloading convention, any library we create should be capitalised and camelcased. In the cases of interfaces and abstracts they should be prefixed with an ''i'' or ''a'' respectively. When you load a Codeigniter library using the Codeigniter loader, it will automatically instantiate the class into an object. So static classes will have to be loaded differently.

Codeigniter also provides a number of system libraries available for you to use. They provide a number of default functionality that we can take advantage of in order to avoid reinventing the wheel. Check out [[http://ellislab.com/codeigniter/user-guide/toc.html|Codeigniter's class and helper reference]] for more information. Many of the functionality you need to run a generic web application is already available.

You can also replace and extend system libraries. You will need to either put them into the ''application/core'' or ''application/libraries'' folder. A good way to know, is to go into the ''system/core'' directory and see if the class you're trying to extend is there, and if it is, then it should be in the ''application/core''. This is how people get customised controllers or loaders.

If you're replacing a native library. You would use the same name of the class you're trying to replace. But inside the class, you would call it CI_CLASSNAME. For example to replace the Email class. You would name it ''Email.php'' and have it run as ''class CI_Email{}''.

If you're extending a native library just declare your class as MY_CLASSNAME extending CI_CLASSNAME. Furthermore if you're using a constructor, make sure to call the parent constructor with:

<code php>
parent::__construct();
</code>

Note that if you're trying use Codeigniter's native libraries or database class inside your own custom library, you need to call the function ''get_instance()''. This is a global function defined by Codeigniter. When you load in your library, that function points to creating an instance to Codeigniter's super object. It's actually a good demonstration of the [[http://en.wikipedia.org/wiki/Singleton_pattern|singleton pattern]]. Every time you call ''get_instance'' you don't actually initialise a whole new superobject. The function checks if the object has already been initialised, and if it has been, it will simply return that object. In the [[http://ellislab.com/codeigniter/user-guide/general/creating_libraries.html|documentation]], it recommends that you assign it to a object member property in your constructor, and then use the variable as if you were calling ''$this'' in your controllers and models.

<code php>
$CI = get_instance();
$CI->do_something_native(); //like $CI->load->other_libary
</code>

However this actually isn't necessary. [[http://stackoverflow.com/questions/7195544/get-instance-in-codeigniter-why-assign-it-to-a-variable|There are reasons for this]].

=== Sparks ===

Before the days of Composer and PSR-0, Codeigniter had its own package and repository manager called Sparks. It is still in use today by legacy Codeigniter libraries and Codeigniter specific packages. So this will still be useful. However it hasn't been kept up to date with the latest develop branch version of Codeigniter, so in order to install we have to make a couple changes. See the [[Solution Stack#sparks|solution stack on sparks]] for more information.

You would have spark packages located at project root, and with the augmented ''MY_Loader.php'' you can load them via ''$this->load->spark('example-spark/1.0.0');'', it is then usable as ''$this->example_spark->method();''. Notice that we can't use hyphens ''-'', when calling methods from classes as it confuses the interpreter as a syntax error. Packages either have to be underscored or camelcased.
==== Composer Libraries ====

Composer is one of the best things to come to PHP since sliced bread. There has been numerous attempts at package management for PHP in the past, but Composer is the best and most widespread in the modern day. Composer is not only an installer tool, but it is also a [[http://phpmaster.com/autoloading-and-the-psr-0-standard/|PSR-0 compliant autoloader]]. What this means it will autoload classes and conform to namespace usage. This allows you to simply call ''new Class'' or typehint interfaces or ''use'' importing without having to actually ''include'' or ''require'' the files that the classes reside in. This magic is performed by modern versions of PHP providing autoload functions that hook into the loading architecture so we can augment it to automatically load what we want given a specified directory, naming style and namespace usage. Composer also allows non-PSR autoloading, so if you have some utility classes that you just want autoloaded, Composer can do that as well.

Try checking out the composer directory, look at how the packages are structured, and the common uses of namespaces in their source code.

However there's a problem. Codeigniter is a framework that caters to older versions of PHP users. So it's not natively integrated into Composer. However there are easy ways of integrating Composer into Codeigniter. Autoloading can be considered a form of bootstrapping. Essentially the autoloader should be available from the very start of initialising a web application. Where is the very start of our MVC architecture? It's in the front controller! So the simplest way of integration would be to simply ''require_once'' the Composer's ''vendor/autoload.php'' in Codeigniter's front controller which is the ''index.php'' at root. It would be [[http://pastebin.com/6ffYwdkf|somewhere at the end but before Codeigniter loads all the controllers]], or else we'd try to load classes before the autoloader is registered.

However there is a better way, and in fact this "Polycademy" way actually gives us autoloading on your Codeigniter's ''application/libraries'' and ''application/third_party'' for free, and is more semantic with Codeigniter's architecture.
==== Autoloading ====

Codeigniter provides a [[http://ellislab.com/codeigniter/user-guide/general/hooks.html|hook API]] so we can plug in our own middleware. The one we're interested in is the most earliest, that is the pre-system hook. This is where we're going to place our Composer bootstrap and our own PSR-0 compliant autoloader.

  - Enable hooks in ''config/config.php''.
  - In your ''config/hooks.php'' define: <code php hooks.php>
//pre_system autoloader
$hook['pre_system'] = array(
    'class' => 'Autoloader',
    'function'  => '__construct',
    'filename'  => 'Autoloader.php',
    'filepath'  => 'hooks',
);
</code>
  - Then download this [[https://github.com/Polycademy/CiAutoloading|Autoloader.php]] into ''application/hooks/Autoloader.php''. (You should also try to read and understand the code, refer to documentation for commands you don't know).

Now you can auto instantiate objects and call static methods from static classes anywhere, and that means both packages in Composer and packages/libraries in your ''application/libraries'' or ''application/third_party''. However when constructing your library classes, do not use underscores in your filenames (excepting folder names) as they will be translated into directories. You need to follow the [[https://github.com/php-fig/fig-standards/blob/master/accepted/PSR-0.md|PSR-0 rules]] now. Capitalised and camelcased!

However if you classes that extend CI's native classes, you will not be able to autoload them. This is because the system classes that your classes are extending/replacing are not autoloaded as they are in the system directory. You'll need to use the native loader to load them. This does not conflict with the native loader.

At this point you have a flexible system utilising Composer, Sparks, Native CI and your own PSR-0 or class map loader.

In order to autoload classes in directories, you'll have to use namespaces.
==== Namespaces ====

Namespaces are a way to encapsulate objects in order to avoid naming conflicts and shorten long path names to aliases. In your operating system you may have two files with the same name and extension. However they can never live in the same directory, because that would cause a naming conflict, and if you're trying to call that file, the operating system wouldn't know which one you're trying call.

Namespaces in programming operate similarly. Imagine you're working in a team, and one of you defines an object called ''class MyDB'', and your teammate who didn't know better also defined an object called ''class MyDB''. Then if you include the files together into one script, this would cause a naming conflict. Previously we would just name one of the classes with a prefix such as ''class SteveMyDB''. However this is ugly and inefficient. Instead we use namespaces to avoid changing our class names. In PHP only classes, interfaces, functions and constants are affected by namespaces. It is recommended best practice to only have one namespace per file.

There are two syntax commands in creating and importing namespaces. They should always be used at the top of the code in the file. You cannot use them in blocks or conditionals.

<file php SomeClass.php>
//use 'namespace' to define the namespace for the current code
namespace Polycademy\MissonChecker;

//use 'use' to import other namespaces into the code or as an alias
//the use command cannot import functions or constants, which is why we follow OOP
use Polycademy\Abstracts\aArmor;

//via the autoloading mechanism, the aArmor will point to Polycademy/Abstracts/aArmor.php then initialise the aArmor abstract, this will be done automatically
class SomeClass extends aArmor{}
</file>

<file php aArmor.php>
namespace Polycademy\Abstracts;

abstract aArmor{}
</file>

When using namespaces, you need to abide by a similar directory structure. The above code defines the namespace as in Polycademy\MissionChecker. This means ''SomeClass.php'' exists in ''base/path/Polycademy/MissionChecker/SomeClass.php''. As you can see the namespace is always defined at where the file is, but does not include the filename itself. The ''base/path'' is defined in your autoloader. If you choose to use CiAutoloading, then the base path is at Codeigniter's ''application/libraries'' and ''application/third_party'' folder. CiAutoloading also includes the Composer's own autoloader which has extra features. The ''use Polycademy\Abstracts\aArmor'' actually imports the file itself, it's not just pointing a directory. You can make ''use'' import a directory, however then when you call objects this will require you to append the directory name, so it's easier to import a file. Here's an example of the directory structure using Codeigniter and CiAutoloading.

    application/libraries
      |
      |----Polycademy
              |
              |----MissionChecker
              |       |
              |       |----SomeClass.php
              |       
              |----Abstracts
                      |
                      |----aArmor.php

The namespaces are always referred to from the root of the base path. There can be further directories or less directories if you wish.

Do note it is possible have [[http://www.php.net/manual/en/language.namespaces.definitionmultiple.php|multiple namespaces in one file]], however this is a bad practice as it will confuse you and other developers who expect namespaces as directories.

Namespaces come to life when using autoloaders, especially PSR-0 compliant autoloaders. According to the PSR-0 rules, you have to namespace and structure your packages in this way:

  - A fully-qualified namespace and class must have the following structure \<Vendor Name>\(<Namespace>)*\<Class Name>.
  - Each namespace must have a top-level namespace ("Vendor Name").
  - Each namespace can have as many sub-namespaces as it wishes.
  - Each namespace separator is converted to a DIRECTORY_SEPARATOR when loading from the file system.
  - Each underscore in the class name is converted to a DIRECTORY_SEPARATOR. The underscore has no special meaning in the namespace.
  - The fully-qualified namespace and class is suffixed with .php when loading from the file system.
  - Alphabetic characters in vendor names, namespaces, and class names may be of any combination of lower case and upper case.

So in our example the vendor name would be "Polycademy", the next namespace should be the package name. In our example that's either MissionChecker or Abstracts. The 5th rule is why we camelcase our filenames and class names. Most packages that are on Composer follow this structure, but not all of them follow it strictly. It is possible to skip having a vendor name, and just have the package name, and it's also possible just to autoload classes without namespaces by defining them as a classmap. Refer to [[http://getcomposer.org/doc/04-schema.md#autoload|autoloading on Composer]] for more information on that.

As a recommendation when constructing your own libraries, try conforming to "Package/Library" style naming. If you are intending to share it, be PSR-0 compliant with "Vendor/Package/Library" style. However if you're importing third party libraries that are neither Composer or Sparks, then you should try to convert them into "Vendor/Package/Library" style. These would then be put in the third party folder.

There are couple other important facets of namespacing that may be a bit confusing to a beginner. It's easier to explain this via code. Also note the [[http://www.php.net/manual/en/language.namespaces.nsconstants.php|namespace constants]], which you can use to explicitly refer to the current namespace if importing imports classes of the same name.

<file php Mapper.php>
//assume autoloading is setup

//ok so this file is in Guzzle/Url directory
namespace Guzzle\Url;

//we're importing something we want to use
use Guzzle\Cookie\CookieParser;

//here we're importing, but we're aliasing it too!
use Guzzle\Message as Awesome;

//here we're importing a directory, just imagine that it is a directory and not a file
use Guzzle\Directory;

class Mapper{

    public function __construct(){
    
        //there's never any need to specify filename extensions, the classes and files are the same name.
    
        //this works, because we imported the file (remember that class names should match file names)
        //it first looks at the current namespace, then the imported namespace
        //this is called an unqualified name
        $cookie_parser = new CookieParser; 
        
        //this may work, it's not imported, so the current namespace gets appended
        //it will only work if there was a Guzzle/Url/UrlParser.php
        //this is also called an unqualified name
        $url_parser = new UrlParser;
        
        //this is called a qualified name, the current namespace gets appended to it
        //it becomes Guzzle\Url\Another\Parser.php
        $another_parser = new Another\Parser;
        
        //this is called a FULLY qualified name, it does not append any of the current namespaces, and it does not recognise imported namespaces. It's like an absolute path.
        $absolute_parser = new \Other\Cool\Parser;
        
        //this uses an alias, and resolves to Guzzle\Message\Parsing.php
        $aliased_parser = new Awesome\Parsing;
        
        //this is not an alias, instead it points to the Directory import. So it resolves as Guzzle\Directory\SuperParser;
        $directory_parser = new Directory\SuperParser;
        //therefore if the use keyword points to a directory and not to a specific file, all of those files become fair game. However you need to use the last namespace directory and prefix all class initialisations
    
    }

}
</file>

The above code would correspond to this kind of directory structure:

    application/libraries
      |
      |----Guzzle
      |       |
      |       |----Url
      |       |       |
      |       |       |----Mapper.php
      |       |       |
      |       |       |----UrlParser.php
      |       |       |
      |       |       |----Another
      |       |               |
      |       |               |----Parser.php
      |       |       
      |       |----Cookie
      |       |       |
      |       |       |----CookeParser.php
      |       |
      |       |----Message
      |       |       |
      |       |       |----Parsing.php
      |       |
      |       |
      |       |
      |       |----Directory
      |               |
      |               |----SuperParser.php
      |
      |----Other
             |
             |----Cool
                     |
                     |----Parser.php


==== Static Classes =====

Static classes are actually classes that have static member properties or methods. These properties and methods can be called without instantiating the class. They almost do the same thing as a procedural function list, however they are more flexible to use and more consistent with OOP usage.

Static classes are alternatives to procedurally defining a large amount of helper functions that simply operate on data without storing any state itself. It's better to use static classes in OOP for two reasons. Firstly it's the consistency with the rest of your OOP architecture, and secondly static classes can be autoloaded, whereas function lists cannot.

Static classes are not instantiated. So you don't call ''new StaticClass;''. You can call the class functions directly.

<code php>
class StaticClass{

    public static function say_something(){
        
        echo 'What!';
        
    }

}

//call them directly like this
StaticClass::say_something();
</code>

The reason you cannot instantiate static classes, is because they don't store any state, they simply operate on other object's data. Therefore it doesn't make any sense to instantiate them. As instantiation is for the purposes of having same class (blueprint) be used for different object representations.

Inside a static function, the normally available ''$this'' keyword is no longer available. The ''$this'' only exists when the object is instantiated. Since static classes are not instantiated, in order call it's own class methods you have to use the keyword ''self''.

<code php>
class StaticClass{

    public static $static_variable = ' Dude!';

    public static function say_something(){
        
        echo 'What ';
        self::other_func();
        
    }
    
    public static function other_func(){
    
        echo ' Ever';
        //notice how in instantiated objects we use $this->static_variable; Here we're using self::$static_variable
        echo self::$static_variable;
    
    }

}

StaticClass::say_something();
</code>

We would put any static classes into our libraries folder. You won't need many static classes, as most things should be instantiated objects. But if you have a bunch of functions related to each other that don't store any state in variables, then you can use static classes.

===== Database =====

Databases are where we store overall application state in the long term. Programming code that stores state, only store the state during the running of the session. In the case of PHP, unless you're running a daemon, this only during the request and response cycle. Which means everything gets reset to their default status and the variables won't hold anything until you startup the program again. Therefore we need databases.

There are many databases catered to many different situations. The one that we're going to be using is MySQL, which is the most popular relational database management system, and one more the flexible ones.

Think of databases like Microsoft Excel. The excel program you're running can be thought of as an database instance. The excel document you opened can be thought of as the database. Each sheet in excel can be thought of as a table. Each table or sheet can have a large amount of columns and rows. We store data in a tabulated form, with each row denoting a section of related data, and each column being the type of the data. All of this is stored in multiple tables, and each table represents a plurality of related data.

If you think about a blog. There would be a blog table. The table can have 5 columns being id, author, title, content and date. Each blog post occupies a row taking up those 5 columns. So the first blog post may be '1', 'Roger', 'The Beginning of the End', 'Today we went on a fishing trip, I saw lots of fishes. Then we went home.', '2013/01/01'. Each blog post after the first would do the same thing.

Database software usually don't have a GUI that comes with it. You would normally have to interface it using the command line. However the PHPMyAdmin adds a web based GUI to any MySQL databases, so you'll do most of your database work there. For other databases, you have to find other GUIs. When interfacing with the database in programming, you would use an abstraction layer such as Codeigniter's Active Records or PHP's PDO extension.

{{ youtube>4XX7X7upEIU&list=PLwwh-11EOGvMTTrLIdKsmEpn0C0nk9CRQ?large }}

Before we start using the database, we should get acquainted with some of the architectural concepts in using databases. It's important to understand that databases are not part of your application server. They are a totally different long running process (it is persistent and not part of the request and response cycle) that is running and your programming in the application server connects to it and interacts with its API.

==== SQL and NoSQL ====

You may have heard the terms SQL and NoSQL. SQL stands for "structured query language", and NoSQL means "not only structured query language". Since the 1970s it has become a standardised and popular language that interfaces with relational (tabular) based databases. Now when people talk about SQL databases, they mean not only that the database's API require you to use SQL, but that the database is relational.

{{ vimeo>46886385?small}}

NoSQL arrived on the scene recently in 1998, and has become more popular in recent years. Essentially NoSQL databases don't conform to the relational model, so they don't store data in a tabular format. They also don't use the SQL language as an API. NoSQL databases are useful for data that don't conform or are easily represented in tabular format. Some NoSQL databases are faster than SQL databases, simply because SQL databases usually have more checks and balances to keep the data reliable.

[[http://kkovacs.eu/cassandra-vs-mongodb-vs-couchdb-vs-redis|NoSQL is not one type of database]], there are many different ways of storing data outside of relational databases, however the topic is beyond the scope of this course. You can find out more in the [[wp>NoSQL|wikipedia article on NoSQL databases]].

There are two NoSQL databases that have become popular and can be used for general applications. They are [[http://www.mongodb.org/|MongoDB]] and [[http://redis.io/|Redis]]. The blog example can be easily replicated in MongoDB. The key difference between MongoDB and MySQL that is quite important for you as a startup to realise is this: One of the reasons MongoDB is faster than MySQL because it has poorer ACID transactional support.

What are ACID transactions? Well first transactions are a unit of work performed within a database management system, and treated in a coherent and reliable way independent of other transactions. Transactions are used when you need that unit of work to be reliable even if the system crashes or bugs out and the unit of work stops either completely or partially. This unit of work needs to be isolated from the rest of the system, so there is no side effects from any erroneous operation. [[http://en.wikipedia.org/wiki/ACID|Transactions need to be ACID]]. This means atomic, consistent, isolated and durable.

  * Atomic means the transaction is all or nothing.
  * Consistent means that completing any transaction must keep the database valid, that is the transaction needs to conform to any data entry rules.
  * Isolated means that if transactions are performed concurrently, the state of the system should be as if the transactions were performed one after the other. This could mean that the database is locked for a transaction and is opened when it finishes.
  * Durable means that once a transaction completes, the data needs to be stored permanently to disk even if the system crashes straight afterwards.

ACID transactions are paramount for databases doing financial work. Imagine you went to an online store and bought a game. You put in your credit card details and click purchase. The system at minimum is doing two things. It is logging your credit card to the financial company, and then putting a record into its sales/delivery system. So that your money gets processed and your good gets delivered. But what if halfway through this process, the system unexpectedly crashed? If the transaction was not ACID, then your money gets processed, but the purchase/delivery order wouldn't be placed!

MySQL and most other SQL databases have good transactional support, and you can setup [[http://ellislab.com/codeigniter/user-guide/database/transactions.html|transactions using Codeigniter's active records]]. This abstracts the process making it easier to work with. Do note that the [[http://www.kavoir.com/2009/09/mysql-engines-innodb-vs-myisam-a-comparison-of-pros-and-cons.html|MySQL table needs to be setup with the InnoDB table engine]] to have transactions.

So when choosing between using MongoDB or MySQL. If you the data you're trying to store naturally comes to mind as a relational data, that is data in tabular format that have relationships to each column, then choose MySQL. If your data doesn't fit that and comes to mind as an object that could have a variable number of columns (thus variable number of properties), choose MongoDB. If you need transactions, always use a SQL database.
==== Database Planning ====

The complexity of your database depends on two things. Firstly the quantity and coherence of your data set, and what kind of questions and answers you want to extract out of your database. For relational databases, there are two concepts that are important in planning out your databases. The first is designing your [[wp>Database schema|schema]], and the second is [[wp>Database normalization|database normalisation]].

For most web applications, unless you're operating on big data, your schema planning should be fairly straight forward. However sometimes your web application will grow a bit more complex, and perhaps you want to extract insight from the data you have. This knowledge area is out of the scope of this course, however you can refer to the these tutorials if you want to learn more:

  * [[http://net.tutsplus.com/tutorials/databases/visual-database-creation-with-mysql-workbench/|Visual Database Schema Creation with MySQL Workbench]]
  * [[http://www.dreamincode.net/forums/topic/179103-relational-database-design-normalization/|Database Normalisation Tutorial]]

=== Data Types ===

For pretty much every table you create, you'll need at least an ''id'' column, which would be the unique number pointing to any particular row of data. This ''id'' column needs to have a datatype of integer or larger, and it should have the property of ''AUTO_INCREMENT'', and you should also position it as the primary key. The property of ''AUTO_INCREMENT'' makes the row automatically increment the number as you insert more data even if you don't insert anything into it (this is why we don't have to worry about it when inserting new rows in the model). Making it the primary key makes MySQL index the ''id'' column and gives it precedence making any look up queries with a matching id super fast.

You should also take care to choose the correct data type for each column. Use ''VARCHAR'' for any text with a set number of characters. Use ''TEXT'' when you don't know how the long the data will be. Use ''FULLTEXT'' when you're indexing it using MyISAM tables. Use ''TINYINT'' if it's a binary true/false boolean data field. You can find out more at [[http://dev.mysql.com/doc/refman/5.0/en/data-types.html|MySQL's documentation on data types]].
==== Active Records ====

When interfacing with a database programmatically, it's best practice to use a library to abstract the process of connecting to the database and also provide a standard API to all the different database commands. This is because although many SQL databases use SQL, they often have differences in their SQL commands. It's far more easier to have a library remember all these commands then you writing different commands for different databases.

Another reason to use libraries is security. A library will often force you to conform to a certain of writing SQL commands, and libraries would automatically escape your SQL commands to prevent any injected SQL destroying your database.

For PHP in general, one the best native extensions to use is [[http://php.net/manual/en/book.pdo.php|PDO]]. However for Codeigniter, it has a native library called [[http://ellislab.com/codeigniter/user-guide/database/active_record.html|Active Records]], and it's simpler to use. Refer to Codeigniter's documentation on the Active Records API for more information. Do note that Active Records is a subset of Codeigniter's overall [[http://ellislab.com/codeigniter/user-guide/database/index.html|Database class]]. The database class provides much more functionality.

=== Codeigniter Database Configuration ===

For Codeigniter you should be configuring [[http://ellislab.com/codeigniter/user-guide/database/configuration.html|your database's connections in the configuration directory]] ''application/config/database.php''.

Your [[http://ellislab.com/codeigniter/user-guide/database/connecting.html|database can then be autoloaded]] through Codeigniter's ''application/config/autoload.php'' and always switched on no matter which the user is on.

You should set your ''db_debug'' option to false during production and if you're explicitly logging the database errors as shown in the MVC model section.

Note to access database errors when ''db_debug'' is off you need to use these two undocumented properties:

<code php>
$num   = $this->db->_error_number()
$msg = $this->db->_error_message();
//this is also useful to examine the actual query passed into the database
$last_query = $this->db->last_query();

//you can then log it via log_message
log_message('error', 'Problem Inserting to user table: ' . $msg . ' (' . $num . '), using this query: "' . $last_query . '"');
</code>

Refer [[http://ellislab.com/codeigniter/user-guide/general/errors.html|Codeigniter's documentation on error handling]] for more information on logging. Note that because log files are written to disk, this won't work in hosts that don't offer writable directories. Cloud hosts normally don't offer writable directories. However it is possible to make your helper class to log it to a third party or send logs to an email.
==== Search ====

One of the most common things we do on a database is search for data. Actually most of the times we're selecting data that match some condition. That is not considered to be a search problem, it's a matching problem. This section specifically refers to wildcard search using the ''LIKE'' operator or full text search with indexes.

The [[http://dev.mysql.com/doc/refman/5.0/en/pattern-matching.html|SQL ''LIKE'' operator]] works like pattern matching. Essentially when you call something like ''SELECT * FROM pet WHERE name LIKE 'b%';'' and this would get all rows from the pet table, where the name starts with "b" and any number of characters after "b". The "%" sign is a wildcard. If you're looking for a row column to mention the word "cat" anywhere, then you would change the "b%" to "%cat%". And of course if you're looking for something to end in "cat", then it would "%cat". The Codeigniter's Active Records library provides an abstraction for these commands giving you a very simple search functionality. Commonly the ''LIKE'' operator is used to search for tags. Imagine you had a blog post, and each blog post is given a set of tags. Kind of like the tags that Youtube uses for their videos. In order to search for these tags, you would not use the ''WHERE'' operator, you would use ''LIKE'' with ''%tagname%''. If you had multiple tags to search for, you could either use ''AND LIKE'' or ''OR LIKE''. The former makes sure that all tags are present, the latter makes sure at least one tag is present. 

Using ''LIKE'' is highly precise, often you need more fine grained control over you search capability. What if you're searching for "cat", but a tag has "cats". Then the ''LIKE'' operator would not the tag with "cats" unless you explicitly specified them. What about "kittens"? What happens when the data your searching through is larger, like perhaps you're searching through the blog's article content. This is when you need full text search.

[[wp>Full text search|Full text search]] works by first establishing an index of the data. This index often groups related terms together, this is called stemming. For example, the words "drives", "drove", and "driven" will be recorded in the index under the single concept word "drive." It will also ignore stop words such as //the//, //is//, //at//, //which//, and //on//. Then the search algorithm goes through the index instead of going through the raw data. This makes for a faster search on a large amount of content. The balancing act in using full text search is between precision and recall. The ''LIKE'' operator has 100% precision, however it will have low recall. This makes it powerful if you're searching for an exact term. But often we don't know what kind of result we're looking for, so the full text search has higher recall. This however creates the problem of false positives. Results which are irrelevant to our query. There are a number of statistical and algorithmic techniques to improve a search engine, and they are all catered to different situations. You can read more about them on the Wikipedia article on full text search. For our purposes, we can keep it simple and use ''LIKE'' when we're looking for tag like data, and full text search for everything else.

To implement full text search on MySQL, you need to use the MyISAM table engine, not InnoDB. Remember that InnoDB provides transactions and is more efficient for write intensive tables, whereas MyISAM is optimised for read intensive and thus search based tables. You can use both tables together in a single database. Setting up needs to be done when you create the table first, not after you create the table. To setup with the MyISAM engine, you can either use PHPMyAdmin's GUI, [[http://www.ignoredbydinosaurs.com/2012/05/database-migrations-codeigniter-101|Codeigniter's DBForge]] or straight SQL such as this:

<code sql>
CREATE TABLE pages (
  id int(10) UNSIGNED NOT NULL AUTO_INCREMENT,
  url text NOT NULL,
  title text NOT NULL,
  content text NOT NULL,
  updated datetime NOT NULL,
  PRIMARY KEY  (id),
  FULLTEXT KEY content (content)
) ENGINE=MyISAM
</code>

If you already created the table, you can alter the table's engine using the [[http://dev.mysql.com/doc/refman/5.0/en/alter-table.html|ALTER TABLE]] syntax. Although it's easier to use PHPMyAdmin's GUI. We're going to start using the database migration tool via Codeigniter's DBForge, so we can keep our database's schema synchronised between development servers. Do note that DBForge currently doesn't support changing the engine of the table, so you'll need to add an additional command using standard query methods.

<code php>
//refer to migrations section to learn more about why we're doing this
$this->db->query('ALTER TABLE  `table_name` ENGINE = MYISAM');  
</code>

Active Records by itself does not have abstracted methods for full text search. However it is possible using the ''$this->db->where()'' method. It has some quirks though. The method by default places backticks on your table and field names. This will corrupt your SQL query. You need to run a command with the 2nd parameter equal to ''NULL'' and the third parameter equal to ''FALSE''.

<code php>
$this->db->where('MATCH (field) AGAINST ("value")', NULL, FALSE);
</code>

To learn about the syntax of full text searches check out these two external resources:

  * http://www.mysqltutorial.org/mysql-full-text-search.aspx
  * http://devzone.zend.com/26/using-mysql-full-text-searching/

You can also elect to use the ''$this->db->query()'' method as an alternative to Active Records. However this does not automatically escape the values for your SQL query opening you up to security issues. You will need to manually escape the values or use query binding. All of this is discussed in [[http://ellislab.com/codeigniter/user-guide/database/queries.html|Codeigniter's documentation on database queries]].

If you have a large amount of content, and search is starting to get slower. You can either re-architect your database using one of the other database stores, or you can integrate the [[http://sphinxsearch.com/|Sphinx search engine]].

{{ youtube>d--v0NhjIfc?large }}
==== Redis ====

Redis is a special database that is catered towards volatile data. This is data in which persistence is not a major issue. It's data you're willing to throw away after finishing the session. It operates like an in-memory key to value data store. This means it is super fast.

Redis in terms of web application development is usually used where memcached was used before. Essentially you can use it for session data, real time messages, publish and subscribing, caching and chat.

We can switch to using Redis for session data if you require that kind of performance. For now we'll stick with working with MySQL, because it's simple and its enough for startup traffic. However if you're interested in hooking up Redis check out these articles:

  * [[http://try.redis.io/|Interative Redis Tutorial]]
  * [[http://phpmaster.com/an-introduction-to-redis-in-php-using-predis/|Introduction to using Redis with PHP]]
  * [[http://www.justincarmony.com/blog/2012/01/10/php-workers-with-redis-solo/|Using Predis as a message queue to pass jobs]]
  * [[http://blog.jmoz.co.uk/websockets-ratchet-react-redis|Redis with Web Sockets]]
  * Libraries for utilising Redis: [[https://github.com/joelcox/codeigniter-redis|Codeigniter Redis]], [[https://github.com/nrk/predis|Predis]] and [[https://github.com/nrk/predis-async|Predis-Async (requires daemon)]]
  * [[http://garantiadata.com/|Redis Cloud Server]] - for using with Cloud9
==== Migrations ====

Database migrations is the process of synchronising your database schema between multiple different development servers and production servers. They are useful when you need to change your development environment to a different computer or when you're working with teams. Do note that migrations are not for synchronising data, it's only for schema changes.

Synchronising code between teams and servers is easy now with the use of Git. However databases require more work to do this. The old way of doing database migrations was to export SQL and its data from your current database, and import into a program that could read SQL and that was connected to the server you wanted to import into. This was a cumbersome method and was inefficient. Instead database migrations are done programmatically through database scaffolding methods. Rather than migrating the SQL. We create the database using an abstraction language, this will contain both the creation and destruction of the schema. We then run this code once and it will create our database for us. When we need to synchronise database schema, we simply synchronise the code and abstraction library, and run the code again on the other server. This way migrations becomes a simple matter of exchanging code via a version control system, and running it once to keep up with your team. If we decided that our latest schema change was incorrect, we can rollback easily because the code to destroy the data was already written and we can just run the destruction portion.

Codeigniter offers its own brand of [[http://ellislab.com/codeigniter/user-guide/libraries/migration.html|migrations]]. To activate migrations, you need to enable it in the ''config/migrations.php''. Polycademy recommends you set the ''migration_type'' to be sequential, as this simplifies the naming of our migrations. The ''migration_auto_latest'' can be set to false, and you don't need to worry about the ''migration_version''.

Next you need to create a ''migrate.php'' controller. You'll have a variation of this code depending on what kind of flexibility you need your migrations to have.

<file php migrate.php>
<?php defined('BASEPATH') OR exit('No direct script access allowed');

class Migrate extends CI_Controller {

    public function __construct(){

        parent::__construct();
        $this->load->library('migration');

    }

    public function index(){
    
        //this code means we're always going to get the latest migrations, that's why we didn't need to worry about migration_version in the migration config.
        if(!$this->migration->latest()){
            show_error($this->migration->error_string());
        }

    }

}
</file>

When you run migrations, you would simply visit that page once. It'll work, and it won't double up even if you visit twice! By the way, for security reasons, you may wish to limit this to be accessible only via [[http://stackoverflow.com/a/11744750/582917|the command line]]. Or only when you're authenticated. Or just disable it during production, but only after you have migrated the schema to the production server.

Now you have the controller and config set up, you need to create your first schema migration. These files would be stored in the ''application/migrations'' folder. Each of these classes would extend ''CI_Migration'' and they would have at minimum two methods. The ''up'' method is called when running the migration. The ''down'' method is called when rolling back. You can roll back by specifying more methods in the migrate controller, or setting the ''migration_version''. We're going to assume that you just want to keep moving forward and not rollback. The names of each migration is prefixed with three numbers. The first schema will always be ''001''. The name of the class will be the same as the filename but without the three numbers.

<file php 001_add_missions.php>
<?php defined('BASEPATH') OR exit('No direct script access allowed');

//notice that the name of the class will be Migration_add_missions whereas the file name is 001_add_missions
class Migration_add_missions extends CI_Migration {

    public function up(){

        //dbforge is already loaded when extending from CI_Migration
        
        //dbforge will notice you're adding a field called id, it will automatically be assigned as an INT(9) auto_incrementing Primary Key.
        $this->dbforge->add_field('id');

        $this->dbforge->add_field(
            array(
                'title' => array(
                    'type' => 'VARCHAR',
                    'constraint' => '100',
                ),
                'description' => array(
                    'type' => 'TEXT',
                ),
                'parameters' => array(
                    'type' => 'TEXT',
                ),
            )
        );

        $this->dbforge->create_table('missions');
        
        //you can also use active records and standard queries to insert raw data (though it's inadvisable except for dummy data like the first login account). You may have to autoload the database library to have it ready

    }

    public function down(){

        //when rolling back all we need to is remove the missions table
        $this->dbforge->drop_table('missions');

    }

}

</file>

Each successive migration will be one number higher than the previous. So the next will be ''002_some_thing_new.php'' with the class name of ''Migration_some_thing_new''. If you have to make changes to your schema, you never edit your previous migration. You always create a new migration to be applied! This is because of the linear history philosophy of migrations makes it easy to rollback. If you're going to go back in time, then you're going to create temporal disasters!

Make sure to refer to the [[http://ellislab.com/codeigniter/user-guide/database/forge.html|DBForge documentation]] for more information.
===== Security =====

Security of web applications is important whenever you're handling user input, user account information or financial transactions. For the purposes of Polycademy, we'll be focusing on input validation, handling passwords, ssl encryption and payments. This section of security sets up the foundation for understanding sessions and authentication. Security is vast area of investigation, check out the [[https://www.owasp.org/index.php/Main_Page|OWASP site]] for more information.
==== Input Validation ====

The most important concept to understand in security is to never trust the user. If your application only pushes out content but doesn't accept any input, then you don't need to really about this. However most likely you'll need to accept some user input, if only to change and edit settings for your web application. The most common implementation of accepting user input is the login and account administration, but any feature that is dependent on user input would apply.

When you accept user input, you could either process the instructions and return the output without any state being kept, or query the state and return the output, or modify the state. The state here would refer to the database state which could be considered the overall application state. When you're just processing instructions, the most important thing is to not allow the user to execute any code that may interfere or cause side effects in your processing. When you're querying or modifying the database state, the most important thing is to prevent your user from querying state they don't have permissions for or modifying state that they shouldn't be able to.

All three of these situations is about first validating that the user has permissions to access the feature you're providing (such as authentication), secondly validating their operations are legal within your rules (such as XSS filtering), and then isolating their operations so they have no undesired side effects (such as SQL injection).

The first validation is a matter of authentication, that is checking if the client is someone that can access your server and applying any permission rules onto their session. This is discussed in the [[#sessions_authentication|Sessions & Authentication]] section.

=== Constraints ===

In the above mentioned second validation, it is a matter of applying constraints onto inputted data. Codeigniter provides us with a [[http://ellislab.com/codeigniter/user-guide/libraries/form_validation.html|validation library]] to simplify the process of constraining form inputs. Remember to setup your validation constraints in an [[http://ellislab.com/codeigniter/user-guide/libraries/form_validation.html#savingtoconfig|external validation config file]] so your controllers can be thinner. You can do this by creating a custom validation config file that is autoloaded, then pass it using ''$this->form_validation->set_rules''.

Here's a list of example constraints you may apply on data input:

  * Required - whether the data was sent in or not.
  * Size limit - in terms of word limit or binary size limit.
  * Data type - was the date really a date? Was the integer really an integer?
  * Match - Did the password entry and password confirmation match?
  * Integrity - Was the email passed in a valid email structure?
  * Allowed - Did the input pass in restricted characters? Such as numbers when you only wanted the alphabet.
  * XSS - Does the input have any scripts inside of it.

The form validation library will allow you to define your own custom callback functions if you need special validation constraints. Codeigniter's form validation library currently works only for forms, and so it is hard coupled to the controller. If you're a MVC purist, you may prefer an ORM or a [[https://github.com/Respect/Validation|data validation library]] which can be used in the model instead.

=== XSS & CSRF ===

Two other constraints techniques are important to overall web application security. They are XSS filtering and CSRF protection.

[[wp>Cross-site scripting|XSS]] or Cross Site Scripting happens when you accept user input and later display on the page to other users. That user input may be a cracker writing scripts which will then be executed when it is later interpreted by the browser of other users. This is dangerous as it can not only compromise the security of your users, but it can undermine the trust of your customers if they find out that visiting your site is dangerous. This usually happens in forums or places which accept comments. Codeigniter provides a global or granular way of filtering scripts out of form input. For the global option, just set ''global_xss_filtering'' in the ''application/config/config.php'' to true. However this may affect inputs which you are expecting scripts and not displaying them. It may also slow down your server, since not all user input is displayed back to the page or displayed in a manner in which XSS is possible. So it is often recommended to leave global XSS filtering switched off, and instead only apply it to [[http://ellislab.com/codeigniter/user-guide/libraries/security.html|individual form inputs]] when you're using the form validation library.

[{{ :web_application_development:csrf-diagram.png?200|CSRF Diagram}}]

[[wp>Cross-site request forgery|CSRF]] or cross site request forgery is a slightly more complicated attack method. Basically a cracker creates a website that looks legitimate, but contains hidden javascript or links that point to your website's form or RESTful resource that requires authentication. Now the cracker needs to trick a user of your web application to come to his/her website. If that user has been authenticated to your website via a cookie based session, and if that session has not died or that user clicked "remember me" on the login, then the cracker's website can extract that cookie session and use it to authenticate its own request to your web application. This is why it's called cross site request forgery, because it's exploiting the trust of the user to forge a request to your web application. If you don't have CSRF protection, then the cracker now has access to your system via the user's credentials. This could be disastrous for not only your service if that user has high level permissions, but can also be disastrous if the cracker gains financial or private information of that user from your web service.

CSRF can be defeated by using CSRF tokens. Essentially on every page load, a CSRF token will be generated, and placed in the user's cookie and also on the page form that is to be submitted. When the form is submitted, the token is compared to the cookie's token to see if they match. If a third party were to post the form, they would have a different CSRF token to the token stored in the user's session cookie. This would render their request invalid.

Codeigniter provides CSRF protection natively. The settings are located in the ''application/config/config.php''. Make sure ''csrf_protection'' is set to true. Now when the user comes into the page, the CSRF token will be set as part of their cookies. Check this out by going to Polycademy.com or PHPBounce and check the cookies tab in Firebug. However in order to set it on any form inputs, you need to use the ''form_open'' function that is part of the [[http://ellislab.com/codeigniter/user-guide/helpers/form_helper.html|Form Helper]]. This is documented in the [[http://ellislab.com/codeigniter/user-guide/libraries/security.html|Security Class]]. ''form_open'' will automatically add a hidden input field with the CSRF token. However if you cannot use ''form_open'', you can use ''$this->security->get_csrf_hash()'' and ''$this->security->get_csrf_token_name()''. You can see these methods on the [[https://github.com/EllisLab/CodeIgniter/blob/develop/system/core/Security.php#L243-L269|Security class on the github repo]]. The CSRF token will be automatically validated on only and every POST requests. Whenever the [[http://ellislab.com/codeigniter/user-guide/libraries/input.html|Input class]] (which is natively autoloaded) detects a POST request, [[http://stackoverflow.com/a/6244868/582917|it will call on CSRF verify from the Security class]].

One more thing, to use CSRF or XSS clean, you need to setup an encryption key in your ''application/config/config.php''. This will be used by the security and encryption class to encrypt hashes and keys for you. Just randomly select 32 characters as your encryption key. Make sure to change it before going into production.

=== Isolation & Preventing Side effects ===

Finally the third validation is about isolating user input. There are two possibilities where user input may cause side effects. The first is code injection, and the second is [[http://php.net/manual/en/security.database.sql-injection.php|SQL injection]]. We already addressed front end code injection through XSS filtering, but preventing back end code injection is even easier. [[http://stackoverflow.com/a/951868/582917|All you have to do is to not use ''eval'']]. Basically don't execute or run anything the user gives you. You shouldn't store code in the database either. (Evalling can get quite complicated if you're trying to implement something like PHPBounce!)

The second is a more pertinent problem. When we run SQL queries, such as searching for some rows which has the field name matching to some user inputted name, then we run the risk of that user inputted name not being a name and being an extra SQL instruction, such as drop table. To prevent SQL injection, we first escape the input, this means putting backslashes on any operators so they are interpreted as text. This was the original method of protecting against SQL injection. However this has been deprecated as it is not foolproof and it was an ugly method of writing a function for each input. Instead bound parameters have been suggested, where you setup a SQL template and then insert the variables. MySQL will never interpret the inserted variable as SQL.

However, since we're using Codeigniter's active records, we don't need to worry about this at all. Codeigniter will automatically escape and bind any of our variables. Unless we're using the standard query method, because that's a raw anything goes method for complex queries that active records doesn't provide. So yay for frameworks!

=== AJAX & CSRF ===

When using AJAX, there's three problems you have to solve in order to implement it with CSRF. The first problem is that the CSRF is validated on any POST requests. If you were using AJAX to serialise a form entry that was used with ''form_open()'', then it would work, because Codeigniter automatically added the CSRF token as a hidden input field. However if you were to submit POST requests outside of a form input, such as through submitting some action via a button, then the CSRF would not validate because there was no CSRF token sent through with the request. In order to solve this problem, you need to capture the CSRF token from the cookie with javascript, and inject it into your AJAX POST requests. There's a couple methods of doing this:

  * http://jerel.co/blog/2012/03/a-simple-solution-to-codeigniter-csrf-protection-and-ajax
  * http://aymsystems.com/ajax-csrf-protection-codeigniter-20
  * http://blog.biernacki.ca/2011/12/enabling-csrf-protection-in-codeigniter-for-ajax-calls/
  * Simply use ''$this->security->get_csrf_token_name()'' and ''$this->security->get_csrf_hash()'' and pass them to javascript variables.

The second problem is of CSRF regeneration. In the ''application/config/config.php'', there's an option to regenerate CSRF. This would regenerate the CSRF on each POST request. This would work fine in a page load based form. So every time you submitted the form, the page reloaded with the new CSRF code. However when you're using AJAX to submit POST requests, then the page doesn't get reloaded. When you submit another request or concurrent asynchronous requests, then the CSRF gets regenerated on the server, but the client side still has the old CSRF token. The easiest way to resolve this is to simply disable CSRF token regeneration. However a more complex method may involve extracting the CSRF token from the AJAX response and refreshing the token on the client side's cookie and CSRF variable via javascript. This will require you to pass back the CSRF token on each response on the server side though.

The third problem is the newer RESTful HTTP methods called PUT and DELETE. The CSRF is not validated when you send in a PUT or DELETE request. In order to do so, you'll need to extend the Security class with a custom class and add in a new method similar to the ''$this->security->csrf_verify()'' method. You'll need to remove the conditional checking of POST requests, since you're trying to do this for PUT and DELETE requests. Remember you're not removing the native method, but adding a newer one. The native one gets called by the Input class automatically, so you don't want to break the Input class's dependencies. Once you have the custom library loaded, you simply call your version of ''csrf_verify()'' on any controller that receives PUT and DELETE requests. However this may not be required since [[http://stackoverflow.com/a/11972282/582917|PUT and DELETE requests are difficult to use when attempting a CSRF attack]].
==== Handling Passwords ====

When you start to have user accounts, you'll need to figure out how to handle passwords. [[http://www.phptherightway.com/#password_hashing|The trick is never store raw passwords in your database]]. You need to encrypt all passwords and only store the hash in the database. When the user submits their password, you encrypt it in the same manner and you compare the hashes, not the raw passwords. What this means is that if someone else got access to your database, they still wouldn't be able to figure out that the real password was. It also means you as the developer won't know what the real passwords are. This is why when you forgot your old password, most secure web applications ask you for a new one, there's no way to get the old one back.

Encryption is a vast knowledge area that is beyond the scope of this course. There are weak encryptions and there are strong encryptions. The term encryption technically refers to two way encryption that is the ability of encrypting and decrypting data. For passwords, we only want one way encryption. The technical word for this is hashing. Hashing by itself is not enough. Crackers can use a [[wp>Rainbow table|rainbow table]] with precompiled collision lists of source input and corresponding hash, and match those to your hashes (if they got access to it) and acquire a list of source input. This is why password hashing involves on extra step called [[wp>Salt (cryptography)|salting]].

The recommended encryption method as of now is [[wp>bcrypt|Bcrypt]]. You can use the bcrypt encrytion method via the ''crypt()'' native PHP function. This is explained in the [[http://stackoverflow.com/a/6337021/582917|Stackoverflow post on bcrypt hashing]]. The [[http://www.php.net/manual/en/function.crypt.php|crypt function]] will automatically add a salt to your passwords, so you don't have to worry about that.

However there is a new native password hashing function that is on PHP 5.5 or greater. Its functionality is explained in the [[https://wiki.php.net/rfc/password_hash|accepted RFC for implementation]]. Most PHP hosts do not currently run on PHP 5.5, so a [[https://github.com/ircmaxell/password_compat|password compatibility shim]] has been created for hosts running on 5.3.7 or greater. The problem with this is that Cloud9 and Appfog do not currently support 5.3.7. However Pagodabox and dotCloud will work with the compatibility shim. If you intend to use the shim, you'll need to develop locally and host it on dotCloud or Pagodabox. Make sure to check the version of your PHP with the console command of ''php -v''.
==== SSL ====

While the above security measures protect your server from unwanted external attacks, none of them protect the transmission of data over the wire. If you're transmitting sensitive data over the internet such as financial transactions, credit card information or even just user login and password, it's essential to implement SSL.

SSL or secure sockets layer is actually the predecessor of [[wp>Transport Layer Security|TLS called transport layer security]]. However most people still call it SSL. You are accessing a website over SSL whenever you have the HTTPS protocol on your browser's URL location. That means any data you send over to the website and any data you receive from the website has been encrypted against any eavesdroppers. Note that there are complications when you use SSL protected resources with non SSL protected resources on the same page. It's recommended that if you're going to use SSL, just use it for every page, this will simplify the process. Nowadays servers and connections are fast enough to process SSL quickly so there won't be any noticeable lag.

SSL is as much about identification as it is about encryption. So although you can use SSL without buying a certificate from a certificate authority, any external users will get a notice that your certificate cannot be trusted, this is not very good for user experience. Therefore you should buy a real certificate from a real certificate authority. When the client requests a SSL connection, the server sends that certificate, the client validates and uses it to encrypt its request. Then the connection is established, and everything operates as normal. You may need to redirect your users who are attempting an HTTP connection to HTTPS connection. This is how sites like Facebook and Twitter operate, they will always redirect you to an HTTPS connection.

Implementing SSL depends on your host. Refer to the host documentation to install SSL. You will then need to modify some settings on your DNS, .htaccess and your framework code. For example for [[https://docs.appfog.com/customize/ssl|AppFog check their Custom SSL docs]]. 

Remember to use SSL with Codeigniter, you'll need to change your base URL to represent HTTPS protocol and you'll need set the cookies to be delivered over SSL in your ''application/config/config.php''. To modify htaccess settings to redirect all users to SSL connection see this [[http://ellislab.com/forums/viewthread/86113/|forum thread]].

When you're developing on localhost, you won't need to implement SSL until you're ready to deploy. This is because SSL really doesn't have anything to do with the application server, it's all about request and response cycle between the client and the HTTP server. The application server doesn't need to care how its requests and responses are being handled. However if you need to see SSL being done on the localhost check this tutorial on [[http://www.neilstuff.com/apache/apache2-ssl-windows.htm|Apache with SSL on Windows]].
==== Payments & Credit Cards ====

In short don't bother. Leave it to the experts. Have a third party process transactions for you and they will handle any SSL related issues. If you are adamant about implementing this yourself be prepared to shell out a lot of cash and resources, because it's not just about technology, but PCI compliance, legal issues and auditing.

Rather than implementing the merchant processor's own API package you can use the Omnipay package that supports multiple payment gateways:

  * [[https://github.com/adrianmacneil/omnipay|Omnipay]]


===== Sessions & Authentication =====

For there to be users to your web application, you need user accounts. To have user accounts to need to authenticate any login request, and then you need to keep their logged in state persistent on the server or client side, or else they'd have to login on each page request. This is achieved through an authentication system and sessions. When you start to have more complicated user accounts such as administrators, moderators, paying customers or guests, then you need an access control list. Note that the implementations discussed below are based on a non-RESTful system. RESTful systems demand a different philosophy and technical implementation for authentication. For pragmatic reasons we're not going to fully abide by REST, because it's currently too strict and it's more about philosophy than technology.
==== Sessions ====

Sessions refer to the state of a particular user logged into your system and interacting with it. The key to implementing sessions is understanding where this state data is kept. State in terms of web applications should be kept on both the client and the server. The client stores state via an encrypted cookie. The server keeps state in the database. When the user first logs in, the server will setup a cookie with all the user's login data and send it to the client's browser, at the same time it will create a corresponding entry into the database. The cookie will have an expiration date that matches the expiration date in the database. Each time the user requests some resource to the server, the server will check the cookie and match it to the database session data, if they match, it means the user is still logged in and interacting with the system. This is how most web applications authenticate their users. The remember me functionality is based on a long expiration cookie, but eventually all cookies die. Once the cookie is cleared or dead, the user will need to login again to recycle the process.

There are other methods of keeping session state, most of it depends on whether you're talking about the client or server. For clients, one other method is to store the state in the URL as query parameters rather than as a cookie. For the server, one other method involves storing the session data in memory such as memcache or Redis database. PHP also offers native sessions which stores to file disk. However the cookie based with database backend sessions is the easiest and most flexible.

You could implement all of this functionality using raw PHP, but we're using a framework, and we'll also use the [[https://github.com/benedmunds/CodeIgniter-Ion-Auth|Ion Auth]] third party library to abstract the messy HTTP handling.

There's a caveat to all of the above information. In the RESTful standard, state should be kept at the client, and the server should not be transmitting state. This will be discussed in the [[#rest|REST section]]. For now you just have to know that there are alternatives to session state if you need to be REST compliant.
==== Authentication System ====

To implement this system in Codeigniter, you need to first setup your cookie and session settings in your ''application/config/config.php''. The settings are straight forward, make sure to customise the prefix to match your web application's name.

<code php>
//this is the config from PHPBounce! Notice the bounce_ to customise the name of the cookies.

$config['sess_driver'] = 'cookie';
$config['sess_valid_drivers'] = array();
$config['sess_cookie_name'] = 'session';
$config['sess_expiration'] = 7200;
$config['sess_expire_on_close'] = FALSE;
$config['sess_encrypt_cookie'] = TRUE;
$config['sess_use_database'] = FALSE; //we're not using CI's native session database functionality, so leave this false
$config['sess_table_name'] = 'bounce_sessions';
$config['sess_match_ip'] = FALSE;
$config['sess_match_useragent']	= TRUE;
$config['sess_time_to_update'] = 300;

$config['cookie_prefix']	= 'bounce_';
$config['cookie_domain']	= '';
$config['cookie_path']		= '/';
$config['cookie_secure']	= FALSE;
$config['cookie_httponly'] 	= FALSE;
</code>

We won't actually be using Codeigniter's session database store session state serverside, but a third party authentication library called [[https://github.com/benedmunds/CodeIgniter-Ion-Auth|Ion Auth]]. Simply follow the instructions on their Github repository and [[http://benedmunds.com/ion_auth/|official documentation to install]] ion auth. Make sure to use bcrypt for your password handling. This package is kind of ugly, the code has not been formatted well, however it is a rock solid library and easy to customise. Ion auth will actually provide you password handling, authentication, session handling and a simple access control list all in one.
==== Access Control List ====

An access control list is refers the process of validating different users for different levels of permissions. Implementations of an ACL can range from simple group permissions to complicated role based permissions often implemented in forums. Using [[https://github.com/benedmunds/CodeIgniter-Ion-Auth|Ion Auth]] provides a simple group based permission model. Essentially every user is assigned to one group. Instead of storing permission codes into the group's database state, you as the developer simply checks if the user is part of a particular group and then grants or denies permissions.

This is not a robust system since you will need to keep track of all the permissions while writing the code (the permissions are not centralised), and you cannot take advantage of cascading permissions or anything complicated. However it is simple and easy to use and covers most use cases.

If you do need more a complicated permissions system (such as multi-level accounts) consider implementing bitwise/bitmask permissions or use the Zend ACL library (it's part of the Zend framework, but can be used independently).

Refer to these resources for using bits for permission systems:

  * http://alanhollis.com/a-quick-guide-to-using-bitmasks-for-permissions-in-php/
  * http://www.php4every1.com/tutorials/create-permissions-using-bitwise-operators-in-php/

Refer to these resources to use Zend ACL:

  * http://lucdebrouwer.nl/adding-zend-acl-to-codeigniter/
  * http://www.mattstone.me/?p=3
  * http://framework.zend.com/wiki/display/ZFUSER/Using+Zend_Acl+with+a+database+backend
===== .htaccess =====

The [[wp>.htaccess|.htaccess]] file is a directory level configuration file used to configure the HTTP server. It is most commonly used with the Apache HTTP server. It has several common uses in web applications. One of which is authorisation, it is possible for the HTTP server to request authorisation credentials before granting a response. Normally this isn't used due to poor user experience and limited authorisation functionality, instead it is more commonly used to simply deny all access in directories that should not be publicly accessible such your configuration directory or library directory. You'll notice in Codeigniter that there is an .htaccess file placed in every almost every directory, most of which are simply denying all access. Other major uses include URL rewriting, compression and controlling the browser cache. We'll also be using the .htaccess file that comes with H5BP and packaged using Initializr as an example since it implements many of these features by default.

==== URL Rewriting ====

[[http://httpd.apache.org/docs/2.0/mod/mod_rewrite.html|URL rewriting]] means modifying a website's URL so that it looks different. Why would you want to do this? Well one implement is when you're using the front controller method in an MVC web application, then all requests are routed first to the ''index.php'' as the front controller. Any subsequent parameters would be passed in as URL segments to point to any controller and method. This would result into a URL similar to "http://example.com/index.php/controller/method". Having the index.php inside the URL is superfluous, we might as well not have it and have the server expect it by default. We can use URL rewriting to remove the index.php from the URL and preserve the URL's functionality.

Note you need to activate the ''mod_rewrite'' extension to Apache to run this.

<code>
#this section is already provided by H5BP, but we modified to suit Codeigniter, different frameworks will require different options
#this is condtion to check if the module was loaded by apache, most hosts support it automatically
<IfModule mod_rewrite.c>
    #this is an option telling Apache to recognise symbolic links, so if you were trying a URL pointing to a file which was a link to another file, it will follow that link to the real file, the + sign is just for merging any options set previously
    Options +FollowSymlinks
    #turn on the rewriting engine!
    RewriteEngine On
    #these are conditions for the the rewrite rule
    #this condition is true if the terms index.php, images, css, js, robots.txt, favicon.ico do not appear in the URL, if they do, then we don't want to activate the rewrite rule, since this would point to a valid resource
    RewriteCond $1 !^(index\.php|images|css|js|robots\.txt|favicon\.ico)
    #this condition is true if the requested resource is not a valid file
    RewriteCond %{REQUEST_FILENAME} !-f
    #this condition is true if the requested resource is not a valid directory
    RewriteCond %{REQUEST_FILENAME} !-d
    #the below is based on REGEX (it takes the URL segments after the example.com and appends them to index.php, passing it back as the URL to be called) So that way instead of calling www.example.com/index.php/controller, I can just call www.example.com/controler
    RewriteRule ^(.*)$ ./index.php/$1 [L,QSA]
</IfModule>
</code>

When rewriting is setup, Apache first matches the URL against a rule pattern. If it does not match, mod_rewrite immediately stops processing that rule, and goes on to the next rule. If the pattern matches, mod_rewrite checks for rule conditions. If none are present, the URL will be replaced with a new string, constructed from the substitution string, and mod_rewrite goes on to the next rule. If RewriteConds exist, an inner loop is started, processing them in the order that they are listed. Conditions are not matched against the current URL directly. A TestString is constructed by expanding variables, back-references, map lookups, etc., against which the CondPattern is matched. If the pattern fails to match one of the conditions, the complete set of rule and associated conditions fails. If the pattern matches a given condition, then matching continues to the next condition, until no more conditions are available. If all conditions match, processing is continued with the substitution of the Substitution string for the URL.

Another example would be removing or adding in the "www" to "http://example.com". Polycademy recommends you to remove the "www" as it is not necessary either. This shortens the URL making it easier to share. Furthermore by explicitly removing the "www" you remove the possibility of duplicate URLs pointing to the same content. This is important for SEO as search engines do not like duplicate content.

<code>
#this is already activated by default
<IfModule mod_rewrite.c>
    #this is true if HTTPS isn't on, we don't want to mess with that
    RewriteCond %{HTTPS} !=on
    #this cond is true if the HTTP_HOST began with "www" (or else why bother rewriting)
    RewriteCond %{HTTP_HOST} ^www\.(.+)$ [NC]
    RewriteRule ^ http://%1%{REQUEST_URI} [R=301,L]
</IfModule>
</code>

URL rewriting can also be done via the application server using routing functionality, however this does not intercept the connection when it was first made, so you can only point to different resources but not change the URL in the user's browser.

H5BP also provides a large amount of other rewrite rules to make your life easier, you read the comments in the supplied .htaccess file.

To learn more about rewriting, check out this [[http://net.tutsplus.com/tutorials/other/a-deeper-look-at-mod_rewrite-for-apache/|Nettuts tutorial on rewriting]].
==== Compression ====

Compression is the science of using algorithms to concatenate separate files and encode it in a format that reduces redundancy in order to compress the file size. You can then transmit the files over the internet and save time to upload/download and bandwidth. The compressed files will need to be decompressed to be use, because the compressed encoding is not designed to be easily editable. It is possible to [[wp>HTTP compression|compress website content]].

[[http://betterexplained.com/articles/how-to-optimize-your-site-with-gzip-compression/|Modern browsers can accept compressed archives from websites]] and automatically decompress the content before displaying it. While it takes time and resources to compress and decompress content, the size savings in transmission can reach up to 80%. This can seriously improve the transmission performance of your website. You can check the size savings using the [[http://www.whatsmyip.org/http-compression-test/|WhatsMyIPAddress service]] and submit popular websites and check the size savings.

On the client side, browsers will only accept [[wp>gzip|gzip]] compressed content. This is executed when the browser sends an HTTP request to the server. Along with the HTTP request, they add in an ''Accept-Encoding'' field with values of compression types. For example this could be the browser request:

<code>
GET /encrypted-area HTTP/1.1
Host: www.example.com
Accept-Encoding: gzip, deflate
</code>

On the server side, gzipping can take place on the application server or the HTTP server. The Apache HTTP server can take care of this for you. There are two methods of gzipping data using Apache, you can either use mod_gzip or mod_deflate. Both of these are extension modules to the Apache HTTP server. mod_gzip is somewhat more reliable than mod_deflate, however mod_deflate is quicker at compression and decompression. Both use gzip encoding.

H5BP's .htaccess file already by default provides gzipping rules. Note that gzipping is only used on text based files that are delivered to the browser such as HTML, CSS and JS. Images are not gzipped because image formats have already been compressed by virtue of their format. Double compression simply increases the size of the file.

<code>
<IfModule mod_deflate.c>
    #This is using the mod_deflate filter, notice  how we "deflate" the output based on the type of the file. The type of the file is determined by their MIME type. So these are all the kinds of files that H5BP will deflate just before they get sent to the browser.
    <IfModule mod_filter.c>
        AddOutputFilterByType DEFLATE application/atom+xml \
                                      application/javascript \
                                      application/json \
                                      application/rss+xml \
                                      application/vnd.ms-fontobject \
                                      application/x-font-ttf \
                                      application/xhtml+xml \
                                      application/xml \
                                      font/opentype \
                                      image/svg+xml \
                                      image/x-icon \
                                      text/css \
                                      text/html \
                                      text/plain \
                                      text/x-component \
                                      text/xml
    </IfModule>
</IfModule>
</code>

The server sends back an HTTP response similar to this:

<code>
HTTP/1.1 200 OK
Date: Mon, 23 May 2005 22:38:34 GMT
Server: Apache/1.3.3.7 (Unix)  (Red-Hat/Linux)
Last-Modified: Wed, 08 Jan 2003 23:11:55 GMT
Etag: "3f80f-1b6-3e1cb03b"
Accept-Ranges: bytes
Content-Length: 438
Connection: close
Content-Type: text/html; charset=UTF-8
Content-Encoding: gzip
</code>

Notice that the content-encoding has a value of gzip. If we use H5BP's deflate module command instead, then it will use "deflate".
==== Controlling Browser Cache ====

The .htaccess file also has the ability to control the browser cache. Browsers naturally cache the content that it receives so that when you visit the website a second time, it will load the resources from cache rather than reloading it from the server. However sometimes you need fine grain control over how long the resources should be cached and a fallback to cache bust cached items if you need to do a quick change. Again H5BP provides us all this, so you don't need to change anything. The relevant code is:

<code>
<IfModule mod_expires.c>
    ExpiresActive on
    # Perhaps better to whitelist expires rules? Perhaps.
    ExpiresDefault                          "access plus 1 month"
    
    # cache.appcache needs re-requests in FF 3.6 (thanks Remy ~Introducing HTML5)
    ExpiresByType text/cache-manifest       "access plus 0 seconds"
    
    # Your document html
    ExpiresByType text/html                 "access plus 0 seconds"
    
    # Data should not be cached as dynamic websites change this often!
    ExpiresByType text/xml                  "access plus 0 seconds"
    ExpiresByType application/xml           "access plus 0 seconds"
    ExpiresByType application/json          "access plus 0 seconds"
    
    # Feeds change often but not that often
    ExpiresByType application/rss+xml       "access plus 1 hour"
    ExpiresByType application/atom+xml      "access plus 1 hour"
    
    # Favicon (cannot be renamed)
    ExpiresByType image/x-icon              "access plus 1 week"
    
    # Media: images, video, audio
    ExpiresByType image/gif                 "access plus 1 month"
    ExpiresByType image/png                 "access plus 1 month"
    ExpiresByType image/jpeg                "access plus 1 month"
    ExpiresByType video/ogg                 "access plus 1 month"
    ExpiresByType audio/ogg                 "access plus 1 month"
    ExpiresByType video/mp4                 "access plus 1 month"
    ExpiresByType video/webm                "access plus 1 month"
    
    # HTC files  (css3pie)
    ExpiresByType text/x-component          "access plus 1 month"
    
    # Webfonts
    ExpiresByType application/x-font-ttf    "access plus 1 month"
    ExpiresByType font/opentype             "access plus 1 month"
    ExpiresByType application/x-font-woff   "access plus 1 month"
    ExpiresByType image/svg+xml             "access plus 1 month"
    ExpiresByType application/vnd.ms-fontobject "access plus 1 month"
    
    # CSS and JavaScript hardly ever change
    ExpiresByType text/css                  "access plus 1 year"
    ExpiresByType application/javascript    "access plus 1 year"
</IfModule>
</code>

You'll notice how cache control is a simple matter of defining the expiration date of files via their MIME type. The default cache times are quite long, so we need a way to cache bust any items we changed. The simplest way of doing this is simply adding a dummy query parameter to the URL. [[https://github.com/h5bp/html5-boilerplate/blob/master/doc/htaccess.md#cache-busting|However this was not always reliable for clients who were behind a proxy server]]. That's why the file extension cache busting method was produced with mod_rewrite in the .htaccess file. These rules by default have not been activated, you'll need to uncomment out the hash "#" to use them.

<code>
#these rules will need to be uncommented
<IfModule mod_rewrite.c>
    RewriteCond %{REQUEST_FILENAME} !-f
    RewriteCond %{REQUEST_FILENAME} !-d
    #looks for files that have (anything).(any numbers).(js or css or png or jpg or gif) and returns them as (anything).(js or css or png or jpg or gif)
    RewriteRule ^(.+)\.(\d+)\.(js|css|png|jpg|gif)$ $1.$3 [L]
</IfModule>
</code>

This way instead of using query parameters, you can cache bust javascript, css, png, jpg or gif files by prepending random numbers to the file extension. For example to cache bust "main.css", in your HTML, simply link to it by "main.123.css". You do not need to change name of the actual file, just the link to it. So you just change the numbers everytime you make a change to the CSS file. From them on, the new version will be cached appropriately by the browser.
===== Caching =====

Caching is a matter of storing dynamically produced data in a static state so that the data does not need to be reproduced every time it is called. There are many different types of cache and different methods are suitable for different contexts. As a startup you shouldn't worry about caching unless you start to see performance bottlenecks. In the end the browser is the best place to store cache, and that's already been handled by H5BP. Other than that there are mainly three types of caching, opcode caching, file caching and memory caching.
==== Opcode Caching ====

PHP is an interpreted language, so every time it runs, it will interpret and compile it while it runs. Opcode caching is about caching the compiled bytecodes of any particular script, so PHP can simply execute the compiled code without having to interpret and compile again. All of this is already handled automatically by default, so you don't need to worry about it.
==== File Caching ====

File caching refers to how a cache is stored, not necessarily caching "files". File caching is mainly used for either web page output caching or database caching. This is done so to avoid unnecessary database calls or even to shortcut the processing time of any long winded operation. Accessing the filesystem can often be much faster than accessing a database. By the nature of file caching, the host you're using must allow writable filesystems. 

Codeigniter offers two native caching libraries relying on a writable file system. Both are quite simple file caching systems and don't offer granular control over partial data.

  * [[http://ellislab.com/codeigniter/user-guide/general/caching.html|Web Page Output Caching]] - Can only be used on full pages. Best suited for static pages that have to query the database and don't change much.
  * [[http://ellislab.com/codeigniter/user-guide/database/caching.html|Database Caching]] - This caches the results of a database query to file. This is best used for data that users may read a lot but doesn't change much. It does not an expiration timer, so you'll need to manage the cache clearing on other callbacks.

Phil Sturgeon created a [[https://github.com/philsturgeon/codeigniter-cache/|partial caching library]] that is far more powerful and allows granular control over your caching. You'll need to create your own conditionals to either read from cache or do full processing.
==== Memory Caching ====

Sometimes file caching just doesn't cut it, we need access to that data faster. That's when you would start to use memory caching. Storing data into memory is very fast, however it is very volatile, and you can't actually store that much into memory. Therefore memory caching should be used for very short term data and constantly changing volatile data. User account sessions is one aspect that many high traffic web applications cache into their memory.

There are many different implementations of memory caching, and the different methods have different properties especially when it comes to multi-server scaling. Think about it, how can the memory cache extend out to hundreds if not thousands of different servers, and each client may need to access a shared memory space. Again all of these factors are most likely not important at the startup stage. However if you are interested in implementing this you should look into the [[https://github.com/jamm/memory|PHP Memory Cacher library]] that abstracts the commands to store data into memory. It supports a number of different memory caches including APC, Memcache, Redis and Couchbase.

Note that Codeigniter also provides a more powerful caching class called the [[http://ellislab.com/codeigniter/user-guide/libraries/caching.html|Caching Driver]]. It also allows you to specify APC or Memcache. However it's not as good as the PHP Memory Cacher.

Be wary of [[http://en.wikipedia.org/wiki/Race_condition#Software|race conditions]] when you're using memory caching with multiple servers and multiple processes!
===== RESTful Routing =====

Routing refers to the practice of customising the direction of HTTP requests to the designated controller that handles the request. This is not the same as URL rewriting although it operates similarly. Routing does not change the URL in the browser, it simply changes the controller that gets called. Routing usually takes place in the front controller, as the front controller is the gate that accepts all requests. Codeigniter automatically routs requests based on this pattern:

<code>
http://example.com/controller/method/1st_parameter/
# or
http://example.com/directory/controller/method/1st_parameter/
# you can also have multiple parameters (each of these parameters must be accepted by the controller)
http://example.com/controller/method/1st_parameter/2nd_parameter/
</code>

Note that Codeigniter by default does not allow nesting of directory subfolders. You can only go one level deep. If you require deep nesting of your directories, you should either use the [[https://bitbucket.org/wiredesignz/codeigniter-modular-extensions-hmvc|HMVC extension]] or [[http://stackoverflow.com/a/13752487/582917|modify the router class]]. 

However sometimes you do not want to abide by this default pattern. Sometimes you need to customise your routes so that when someone gets ''http://example.com/controller/1st_parameter'', they will actually pointed to ''http://example.com/different_controller/different_method/1st_parameter''. Again this does not change the URL in the client's browser, all of this is done behind the scenes.

To implement custom routes, you can use [[http://ellislab.com/codeigniter/user-guide/general/routing.html|Codeigniter's native URI Routing configuration file]] located in ''application/config/routes.php''.

One question that was often asked by beginning developers is, how best to rout your applications. Before there weren't any conventions or standards as to how URLs should be constructed. However in recent years the REST standard has become mainstream.
==== REST ====

[[wp>Representational state transfer|REST]] stands for Representational State Transfer which was invented by Roy Fielding in his doctoral thesis. To understand REST, you should first investigate the history of the internet. [[http://blog.dhananjaynene.com/2009/06/why-rest/|Dhananjay Nene explains the history of internet and how it led to the REST architecture style]]. Once you have understood where the internet came from, you should read this article on how [[http://blog.dhananjaynene.com/2009/06/rest-is-the-dbms-of-the-internet/|REST can be understood the DBMS of the internet]]. Another good reference is the [[wp>Hypertext Transfer Protocol|Wikipedia article on HTTP]].

REST has emerged as the dominant model of web services. You can think of all the major open APIs such as Facebook's API, Twitter's API and Github's API as REST based. But REST is not just for APIs, in fact the REST movement is about converting all web resources into APIs. If you think about it, your browser is the client, and all servers expose API methods to access its resources and do things to its resources. REST however places constraints on how we expose those API methods.

As explained in the history of the internet, when people started to use the internet for more than just accessing static information or exchanging files, businesses started to create service oriented architectures. These architectures exposed API methods that were called RPCs (remote procedure calls). This style of architecture was neither scalable or efficient. The reason being is that vendors needed to provide an extensive documentation upfront about how to use their API. Each API call was unique to each vendor. There was no standardisation in the way we called the APIs. REST came along and standardised these approaches. The most important constraint of REST is the enforcement of an uniform interface of operation verbs, that were completely independent of the resource type. Basically clients should not need to know what the resource they're calling to understand the operation they are executing. You may start to realise that this is similar  to the concept of interfaces in OOP. Just imagine that all web servers were objects "implementing" the REST interface which defined four methods: (in the case of HTTP) GET, POST, PUT and DELETE.

The next most important constraint of the REST architecture is that every resource on the web has a unique URL. Every resource URL can be called upon using either of the four HTTP methods, and this would do different functions based on what the resource is. Furthermore every resource needs to be manually readable just by the web browser, so that your API users can understand what your API is without having write code. REST style doesn't care what your resource is, that's up to you. It doesn't specify what functionality you're providing, just simply the style of communication between the client and the server. So your resource depending on what the client wants can be requested in different formats (called "Representations"), such as straight HTML, JSON (for AJAX) or even XML. An important thing to understand is that URLs which are resources should be nouns. There should not be any verbs that specify actions in the URLs. The actions are specified by the four HTTP verb methods.

These constraints along with the many other constraints make RESTful web services highly scalable and easy to use. This is why the SOA (service oriented architecture) industry using RPCs is moving towards ROA (resourceful/restful oriented architecture).

The four HTTP methods work like this:

  * GET - this is the simplest type of HTTP request method; the one that browsers use each time you click a link or type a URL into the address bar. It instructs the server to transmit the data identified by the URL to the client. Data should never be modified on the server side as a result of a GET request. In this sense, a GET request is read-only, but of course, once the client receives the data, it is free to do any operation with it on its own side  for instance, format it for display.
  * POST - this is used when the processing you wish to happen on the server should be repeated, if the POST request is repeated, this means they are not "idempotent". You are essentially telling the server to take the request payload and add it as a "subordinate" to the resource. Think of it as a create operation.
  * PUT - is very similar to POST, but is used for updating a resource too. So you're telling the server to "put" the request payload into the designated resource URL. If the resource URL already exists, then it updates the resource. [[http://stackoverflow.com/questions/630453/put-vs-post-in-rest|Therefore it can be used for both create and update operations.]] However most developers would recommend it to keep it as update so you don't get confused.
  * DELETE - this means delete the resource from the designated resource URL.

The four HTTP methods are appended to the HTTP header when the client sends the request. If the resource was ''example.com/blog''. Then we could GET ''example.com/blog'' and retrieve all the blog posts. We could POST ''example.com/blog'' and create a new blog post. In reality the URL would actually be ''example.com/blog/id_of_new_post''. Because it doesn't modify the blog resource, but adds a child resource to the blog resource. We could also PUT ''example.com/blog/already_existing_id'' and it would update the child resource with an ''id'' equal to an already existing id. Finally we could DELETE ''example.com/blog/already_existing_id''.

One thing to realise is that browsers don't currently support PUT or DELETE verbs in normal operation or forms except through XHR AJAX. This means that if you need browser users to access PUT and DELETE actions directly, then they will need to specified as part of their URLs like ''example.com/resource/delete''. This is a violation of RESTful principles but it's necessary. However it they are meant to be accessed through AJAX, then you can force the verbs to be part of the HTTP header when sending the request, and your server will handle the request accordingly.

If the request comes from GET, any parameters should be extracted from the URL using the global variable ''$_GET''. If the request comes from POST. It can be extracted from the ''$_POST'' variable. These are abstracted by [[http://ellislab.com/codeigniter/user-guide/libraries/input.html|Codeigniter's Input class]]. However if you use PUT or DELETE, these do not get automatically put into a global variable you'll need to use [[http://php.net/manual/en/wrappers.php.php|php://input wrapper]]. [[http://stackoverflow.com/questions/8893574/php-php-input-vs-post|This will extract the raw request payload without any processing]]. You may need to use [[http://php.net/manual/en/function.parse-str.php|parse_str()]] function if the payload is serialised key to value format. However a more common data format that gets put into the request payload when using AJAX would be JSON. This would require you to use [[http://php.net/manual/en/function.json-decode.php|json_decode()]]. Make sure to understand how the request payload is structured and plan for it. Doing it properly will avoid the need to painfully debug AJAX request and responses. Using Firebug or other web developer tools will be very helpful in this regard. Remember to XSS clean and validate any of these requests.

Once you've handled the request you need to pass back a response with an [[http://blog.garethj.com/2009/02/17/building-a-restful-web-application-with-php/#returningResponses|appropriate HTTP response code]].

  * 200 OK: successful request when data is returned
  * 201 Created: Successful request when something is created at another URL (specified by the value returned in the Location header)
  * 204 No Content: Successful request when no data is returned
  * 400 Bad Request: Incorrect parameters specified on request
  * 404 Not Found: No resource at the specified URL
  * 405 Method Not Allowed: when a client makes a request using an HTTP verb not supported at the requested URL (supported verbs are returned in the Allow header)
  * 406 Not Acceptable: Requested data format not supported
  * 500 Internal Server Error: An unexpected error occurred
  * 501 Not Implemented: when a client makes a request using an unknown HTTP verb

The 200 status code doesn't actually need to be manually returned, if you return any data, the browser will assume it was a 200 status code. Some of these status codes will be implemented on different levels in your application. For example a 501 error would be implemented at either the HTTP server level or the routing level.

One constraint of RESTful architecture is the concept of stateless server. Essentially the server should not manage the state of the request. Every request is supposed to carry all the necessary payload to authenticate and validate the request, hence "State Transfer" in the REST name. This means servers using database sessions actually violate RESTful style. Note that we're talking application state not resource state. Application state is the state of the client in interacting with your application. [[http://jcalcote.wordpress.com/2009/08/10/restful-authentication/|This is somewhat controversial constraint]]. While there are advantages to stateless servers in scalability, because if you have a million clients, you don't have a million records of session to manage, instead each client simply passes in their authentication token each time they want something, it some what difficult to create a secure authentication method that is good of user experience when complying with statelessness. There are number of methods that are described in the [[#providing_web_services_apis|Providing a Web Service APIs]] section. However you need to balance your effort against your reward. The question to ask yourself is "Are you building a RESTful API which will only be used by your own web based browser clients (that might be a single page application), or are you building a RESTful API for third party web services so they can create mashups?". If your answer is the former, you can then choose to either create a RESTful compliant authentication scheme (difficult) or go with the old cookie database based sessions. If your answer was the latter, then you should definitely create a RESTful compliant authentication scheme, as your clients (who are third party services) will be expecting that, and servers usually don't carry cookies. You can also use a both in a [[http://programmers.stackexchange.com/questions/141019/should-cookies-be-used-in-a-restful-api|fallback strategy to deal with both browsers and servers]].

Now you understand the RESTful standard. The first thing to implement RESTful style URLs through your application's routing feature. You could manually write all the resource routes yourself. Or you can use the excellent [[https://github.com/jamierumbelow/pigeon|Pigeon library]] that is integrated into Codeigniter and can be called from the routes config file. This is just the tip of the iceberg, but you're on your way to a RESTful web application.
==== Handling Output ====

Each resource URL should be able viewable in different formats according to RESTful standards. This is called [[wp>Content negotiation|content negotiation]]. Clients and browsers can specify the data formats they are capable of receiving using the HTTP Accept header. In javacript this can be set using the setRequestHeader method on the XMLHttpRequest object. A normal browser request (meaning navigating using the URLs in the browser) does not add any custom HTTP Accept headers to the request. You can use jQuery or direct javascript to add it in.

On the server side you would receive accept headers by extracting the global PHP variable ''$_SERVER['HTTP_ACCEPT']''. Codeigniter provides an abstraction for this via their [[http://ellislab.com/codeigniter/user-guide/libraries/input.html|Input class]], you can use the ''$this->input->server()'' command. The accept headers will need be parsed using a combination of string functions and regex depending how flexible you want it to be. Most of the times if you're providing multiple response formats, then it's a resource that is to be called from a third party web service, you can simply rely on the first acceptable data format in their request header, since developers using your API would want only one format. Look into this [[http://stackoverflow.com/questions/1049401/how-to-select-content-type-from-http-accept-header-in-php|Stackoverflow question]], [[https://github.com/kwijibo/Accept-Header-Parser|Accept-Header-Parser Library]] and this blog article [[http://bililite.com/blog/2010/01/06/parsing-the-http-accept-header/|Parsing the HTTP Accept Header]] for inspiration.

Since your resources will have different representational formats depending on how the client requested it, this then becomes a matter of handling output. The best way to implement this is through a templating library. The [[https://github.com/Polycademy/CiTemplating|CiTemplating library]] that I discussed earlier is built for this. Simply create different layouts for different representational formats. Now when you need to output HTML, use an HTML layout. If you need JSON, use a JSON layout. The layouts stay the same, it's the data that you inject that changes. By the way JSON doesn't really have a template, because JSON is usually extracted raw using AJAX, and then manipulated by javascript, and then rendered on the client side.

Of course if the data doesn't change much, remember to cache the JSON output!
===== Consuming Web Services APIs =====

Now that you understand how REST works, you pretty much understand how all the major web service APIs work as long as they are not the old RPC/SOAP service oriented architecture. Now instead of manually coding all the granular aspects of HTTP handling and processing the request and response of RESTful architectures, you can use many well tested libraries that developers have created to abstract all those procedures.

API or HTTP related libraries sit on either the consumption side or the provision side. This section talks about consuming third party APIs. This means you need an HTTP client library. Do note however that different HTTP client libraries have support for different authorisation and authentication schemes. All libraries will support basic HTTP authentication passing in username and password with each request, some will support [[http://stackoverflow.com/questions/599048/http-digest-authentication-versus-ssl|HTTP digest authentication]], but you have to watch out for any web service APIs that a rely on Oauth 1.0a or Oauth 2.0. Twitter for examples uses Oauth 1.0a whereas Facebook, Google and Github implemented Oauth 2.0. Many web services are moving from Oauth 1.0a to 2.0 but it will take a long time before Oauth 2.0 becomes a standard. Some of the more basic third party services don't need so much authentication complexity, they simply use private key or HTTP basic authentication. In fact some services have no authentication schemes and you can just query the URL directly.

Here's a list of client side HTTP/REST libraries you can take advantage of. Note that these are for a PHP server to act as a client side to a third party service. If you're intending for the browser to be the client, you'll need to find javascript libraries.

  * [[https://github.com/philsturgeon/codeigniter-restclient|Phil Sturgeon's Codeigniter REST Client]] - This library is integrated into Codeigniter. You can see how to use it on the [[http://net.tutsplus.com/tutorials/php/working-with-restful-services-in-codeigniter-2/|bottom half of his Nettut's tutorial]]. This supports HTTP basic and HTTP digest.
  * [[http://guzzlephp.org/|Guzzle]] - A full featured and well documented HTTP client library. It supports HTTP basic, digest and Oauth 1 authentication schemes.

Of course you cannot just rely libraries, every API has their own documentation. You'll have to read about them in your own time.

You'll notice that almost all APIs requiring any kind of authentication will use a SSL connection with the HTTPS protocol. This is to prevent eavesdropping on your authentication keys.
==== Third Party Login ====

Consuming third party APIs is relatively a straight forward matter once you have understood the fundamentals of REST. However authenticating against third parties is difficult due to the numerous implementations. Before we go further, let's go through a bit of history. In 2005 Brad Fitzpatrick the creator of Live Journal, created [[http://openidexplained.com/|OpenID]]. He called it a distributed identification system. This was the beginning of the concept of third party login systems, that were designed to remove the need to constantly register at sites and forums just access them. After all if everyone was just entering a username, password and email, why can't a trusted authority simply keep a database of these records, and all web services can simply use their records when someone wanted to login? In 2006, Twitter was attempting to integrate OpenID into their systems. At the same time another company Ma.gnolia wanted to authorise the integration of their services into the desktop dashboard widgets. Several developers from these companies met up to discuss how best to implement this system. They concluded that even with OpenID that provided third party login, there were still no standards for third party API authorisation. So they began work on Oauth 1.0 and eventually Oauth 1.0a with security improvements. [[http://oauth.net/|Oauth 2.0]] is now be worked on and many companies have already adopted drafts of the standard, however the standard is still fresh so documentation is few and far between.

In order to future proof this course, we're going to talk about Oauth 2 and not Oauth 1. The Oauth standard has gone through 31 drafts and as of this writing stands on RFC 6749. The [[http://tools.ietf.org/html/rfc6749|complete documentation on Oauth 2 is located on Internet Engineering Task Force's website]]. The important parts of that document to developers is at [[http://tools.ietf.org/html/rfc6749#section-4|section 4]] where it starts talking about the different authorisation flows or schemes that relevant to different contexts. You should start reading from there. Other sources of information include:

  * Aaron Parecki's [[http://aaronparecki.com/articles/2012/07/29/1/oauth2-simplified|simpler explanation of the different Oauth 2 authorisation flows]].
  * [[https://developers.google.com/accounts/docs/OAuth2|Google's Oauth2 diagrams]]
  * [[http://tutorials.jenkov.com/oauth2/index.html|Jenkov's Oauth2 Tutorials]]

The most used flow would be the Authorisation Code Grant flow. We first have to register our web application at the third party web service. They should provide us with our application credentials as a client ID and client secret. We then produce a link on the front end, that points to the authorisation end point which would be at the third party. The user would click on that link and allow our application to access their information. The third party service redirects our user with a URL that has that has an authorisation code as part of the URL query parameters. We would extract this query parameter and call the API end point (which could be the same server as the authorisation end point or different servers) with this authorisation code and exchange it for access token. Finally we use the token and make API calls with that in our HTTP header. This access token may be time limited for a particular session. You can see that there are three separate requests your server is making here. One request for the user to allow access, another request to exchange the authorisation code for an access token, and a final request to the API with the access token.

If we were making a single page application and required third party login without any server side calls, we would use the [[http://tools.ietf.org/html/rfc6749#section-4.2|Implicit Grant flow]] which doesn't expose the client secret.

If you wanted your application to modify its own resources that are on the third party independent of any user logging in, then you would use the client credentials grant flow. Think of it as the software or server logging into its own account, there is no human user involved here.

Another interesting use case would be the single page application logging in via Oauth 2 to our own server based provider. This could use the password grant flow (the user is logging in) or the client credentials (the software is logging in) grant flow. This is discussed in the next section on [[#providing_web_services_apis|Providing Web Service APIs]].

If you want to provide your user the ability to auto login or remember me functionality while using third party logins, you have to make use of the ''refresh_token'' grant type. The refresh token may be optionally provided to you when you exchange the authorisation code to get the access token. So if the third party doesn't provide it, then you can't have auto login with that third party. The access token expires after some time, you'll have to check the particular API docs to see how they represent that. You can constantly use the access token until it expires, in which case the next time your user visits, you'll send a refresh token to acquire a new access token. So make you [[http://stackoverflow.com/questions/9809742/how-to-automate-login-to-google-api-to-get-oauth-2-0-token-to-access-known-user|store the access token and refresh token in your account database]]. This is explained in the [[http://tools.ietf.org/html/rfc6749#section-6|IETF rfc about refreshing access tokens]]. Furthermore in order to have a proper user account database, you would extract the necessary information about the user you need and cache in your database, so that way you don't need to constantly call the third party API for the same information each time your user makes a request.

We have a number of libraries available to abstract all of these authentication schemes and flows.

  * [[https://github.com/philsturgeon/codeigniter-oauth|Codeigniter Oauth 1]]
  * [[https://github.com/philsturgeon/codeigniter-oauth2|Codeigniter Oauth 2]]
  * [[http://hybridauth.sourceforge.net/|HybridAuth]] - probably supports the most amount of schemes and flows. It focuses more on provider integration so it does have support for OAuth 1 and OAuth2.
  * [[https://github.com/mamprogr/CodeIgniter-IonAuth-HybridAuth|HybridAuth combined with Ion Auth]]
  * [[http://opauth.org/|Opauth]] - Inspired by OmniAuth in Rails.
  * [[https://github.com/Lusitanian/PHPoAuthLib|PHPoAuthLib]] - Generic library that supports both Oauth1 and Oauth2.
===== Providing Web Services APIs =====

The internet is becoming more of a neural net of applications than just a large file hosting service. The rise of REST, JSON, AJAX and web services have given even more rise to web mashups and integrations. Some companies have been built through integration into a larger more popular service.

Creating a popular API is probably more about business value than the exact technical implementation. Never the less implementing APIs require a different mind set from just consuming APIs.

The first thing to note is that you should create your APIs from the REST standard. From there you will need to consider what kind of resources you're going to expose, and what you're going to let your consumers do with those resources through the different HTTP methods. Next you'll need to figure out your response formats, basically how your data will be represented and therefore consumed. RESTful philosophy states you should support as many as possible! Afterwards you'll need to consider your authentication scheme, which all depends on how people will be using your API. Are they accessing the user account data so they have third party login, or are they using your service for machine to machine communication and third party processing instead? You should also consider versioning your API, so you can upgrade your API without breaking backwards compatibility. That simply means prefixing all API calls with something like ''example.com/apiv1/resource/parameter'' and then ''example.com/apiv2/resource/parameter''. Finally you'll need to throttle your API calls, so your users won't overload the server. You'll need to consider all the different exceptions and errors that you will output to the client for incorrect authorisation or incorrect HTTP methods.

Most of these implementations are outside the scope of this course, but a lot of that theory has already been covered in previous sections. This section will just focus on provisioning an authorisation scheme and handling RESTful responses. Jamie Rumbelow's book [[https://efendibooks.com/books/codeigniter-handbook/vol-2|CodeIgniter Handbook - Vol. 2 API Design]] is also a good reference if you want to get stuck into this.

==== RESTful Authentication & Stateless State ====

The first thing to do is to go buy an SSL certificate from a valid CA. All Oauth2 connections must be through HTTPS because we are transmitting sensitive data. SSL connections are designed to authenticate the connection to the server, but also identifies the server as trustworthy. In order to RESTfully authenticate the client, we must first understand an important constrant of REST, and that is REST applications are stateless. That is, the server should be not be managing the application state of the user. This means cookies with corresponding database records are not an option. Application state should be handled by the client, not the server. The server only manages resource states. The difference being that application state are variables that are only relevant to one particular client, and hence are volatile and quickly destroyed when the user leaves. Resource states are sharable and persistent and used by all clients.

Now for the purposes of sanity, if you have complex state keeping requirements such as a shopping cart, or you don't think you'll scale out to billions of users, you can relax this constraint. REST is not a religion. Use it when it's practical for you.

However let's investigate our REST compliant authentication or stateless state options.

  * HTTP Basic Authentication - User and Password sent on the HTTP headers each request. This has an ugly log in interface, and lacks a log out capability. Very basic, it's better for machine to machine communication.
  * HTTP Digest - Same as HTTP Basic but now the username and password is encrypted. It still has the same problems as HTTP Basic though, and the encryption isn't strong. Refer to the [[http://php.net/manual/en/features.http-auth.php|PHP documentation for capturing HTTP basic or digest requests]].
  * Query Parameter Authentication - A unique session ID is placed on the URL as a query parameter. This gets matched to a row in a cache or database. This is pretty the same as session cookies, only now the session ID is in the URL. This allows it to be more portable than session cookies, since cookies are part of the HTTP standard, and you may want your REST API accessible by other interfaces. However this has problems since now when people share their URLs they will have their session ID appended to their URLs which make no sense to the new visitor.
  * Implement your sessions or shopping cart as a resource on the server which has a persistent URL associated to each session. You can then use HTTP verbs to manipulate these sessions. This is not truly RESTful since you're just providing a REST interface to the session cookie/database implementation. This does not have the scalability benefits of having application state on the client side.
  * [[http://www.peej.co.uk/articles/no-sessions.html|Use javascript and single page applications to handle state on the client side]]. They will use HTML5 APIs for local storage or other mechanisms to store any application state. A unique identifier or username and password information will still need to be passed to the server for validation however.
  * Provide your own Oauth 2.0 authorisation scheme. This one is the most viable, and you can couple it with the javascript method. 

As I said before. The specific flows when providing your own Oauth 2.0 API depends on the clients who will be accessing it. If it's a web application used by clients who are browsers, this usually means they have user accounts. Since you're the one providing the front end, there will be a trust relationship, so you can use the [[http://tools.ietf.org/html/rfc6749#section-4.3|password grant flow]]. However if it's machines that will be communicating with your API to access their machine user account, or maybe your front end does not require a log in, just a unique application state, then you can use the [[http://tools.ietf.org/html/rfc6749#section-4.4|client credentials grant flow]].

Luckily there's premade libraries that are designed for Oauth 2.0 servers.

  * [[https://github.com/alexbilbie/CodeIgniter-OAuth-2.0-Server/|Codeigniter OAuth 2.0 Server]] - Documentation is sparse on this.
  * [[https://github.com/bshaffer/oauth2-server-php|Generic Oauth2 Server PHP]] - This is the best server based implementation of Oauth 2.0 I've seen and it has good documentation and examples.

Regardless of the authentication scheme, if writing state management in javascript is not your cup of tea, then just stick to simple cookie to database session management. Just remember that in order to scale cookie to database sessions, you'll need a distributed memory caching technology such as memcache or redis, so that it can be accessible across multiple computers.
==== RESTful Server ====

Phil Sturgeon created a [[https://github.com/philsturgeon/codeigniter-restserver|Codeigniter REST based server library]]. It provides basic authentication schemes, HTTP method handling and output format handling. He explained how it works in his [[http://net.tutsplus.com/tutorials/php/working-with-restful-services-in-codeigniter-2/|Nettuts article on the server and client libraries]].

Other implementations include:

  * [[http://www.websanova.com/tutorials/web-services/how-to-design-a-rest-api-and-why-you-should|Websanova's tutorial on REST in Codeigniter.]]
  * [[http://adamwhitney.net/blog/?p=707|Adam Whitney's take on RESTful service in Codeigniter]]

There are also frameworks designed to be used as an API. You shouldn't follow each person's implementation religiously, find what works good for your purposes and just implement it, it's the best way to learn.

==== Debugging APIs ====

Also note that debugging APIs will require the use of Curl. Firebug and associated web developer tools will also help when debugging AJAX APIs.

===== Concurrent Processing =====

Concurrent processing is sometimes necessary when the processing work that is needed to be done will take a longer time than what is acceptable. Operating PHP in a single thread would mean that the user would get no response and could not interact with the user interface until that processing finished. This is not very good for user experience. Common applications involve processing images thumbnails, uploading and encoding video, compiling code, simultaneously sending thousands of emails, producing PDFs and asynchronously querying multiple third party services.

Before we go any further, let's examine what is concurrent processing. Concurrent processing refers to the techniques in making a CPU core multitask across processes. The key point to understand is that there are two kinds of "processes" in computing. There is the proper process that we call "process" and a light-weight process called a "thread". Processes are independent tasks that occupy separate memory space. Threads are processes that share their memory space and are therefore contained within a process. Therefore a single process can have many threads. Single core CPUs implement multitasking by context switching between threads, and have a scheduler that switches between proper processes. This is done at phenomenal speeds, so we get the illusion of multitasking. Multiple core CPUs run multiple processes at the same time, but of course due to thread context switching, we can lots of programs at the same time. We can encode a video, watch Youtube, play music, use Firefox, download torrents, play a 3D game all at the same time. Our computer may slow down eventually, but it all seems to happen at the same time. The creation of extra processes is called "forking" or "multiprocess", whereas the creation of new threads is simply "multithreading". Here are extra resources that you read to understand this in more detail:

  * [[http://www.geekride.com/fork-forking-vs-threading-thread-linux-kernel/|Forking vs Threading]].
  * [[wp>Computer multitasking|Computer Multitasking]]
  * [[wp>Concurrent computing|Concurrent Computing]]
  * [[http://stackoverflow.com/a/14201579/582917|Multiprocess vs Multithreads in PHP]]

The default configuration of PHP makes it difficult to do concurrent processing. There are two reasons, the short lived nature of PHP under the Apache HTTP server and the lack of native multithreading. Firstly when the HTTP server such as Apache executes PHP to handle a response, the PHP does not run for long, Apache or the PHP settings automatically spawns a new process and quickly shuts down the process after a bit of time. This matches the request response cycle of the web, but sometimes you need a long running process to handle large tasks or to act as a kind of "watchdog" that reacts to new tasks without having to be completely initiated each time a task is required to be completed. This can be overcome by using daemons. Secondly the lack of multithreading can be overcome by either implementing a multiprocess architecture instead, or using the new experimental [[http://pthreads.org/|Pthreads extension]]. Multithreading is outside the scope of this course, but do check out the extension if you have special needs. We're going to examine multiprocess architecture and long running daemons.

Native PHP functions allow you to fork off a process so it becomes an independent process. While this does spread the workload, it's not very flexible since you can't get any messages or responses back from the forked working process. It's just a blackbox, you won't even know if it succeeded or not. A better way is using job managing queue and long running worker daemons (or short lived worker processes depending on what you need).

A job managing queue is simply a daemon (a persistent process) that receives messages to manage jobs and then creates jobs by spinning up a worker processes, or passing messages to idle workers to start work. It can then manage them by asking about their status and also passing back responses to the main parent process.

There are two good choices for a job managing queue for PHP:

  * [[http://gearman.org/|Gearman]]
  * [[http://www.zeromq.org/|ZMQ]] - ZMQ is actually much more than just a job manager, read their documentation to find out.

Refer to these blog tutorials for more information on implementation:

  * http://www.lornajane.net/posts/2011/Using-Gearman-from-PHP
  * http://www.mwop.net/blog/240-Writing-Gearman-Workers-in-PHP.html

Please note, that due to your host environments, you may not able to use daemons or worker processes, such as ZMQ or Gearman. dotCloud is one cloud host offering worker processes. Remember to also use [[http://supervisord.org/|Supervisor]] to keep your daemons persistent, it will restart them if they crash.

{{url>http://www.slideshare.net/slideshow/embed_code/2340418?rel=0 427px,356px noscroll noborder}}

An important concept to understand is that using long running daemons instead of Apache's spin up a PHP instance for each request, can be beneficial for different scenarios. A lot of the excitement about Node.js is attributed to its event driven asynchronous non-blocking IO architecture, allowing it to serve many connections. PHP has its own implementations with [[http://reactphp.org/|React]] and [[https://github.com/shaneharter/PHP-Daemon|PHP-Daemon]].

==== Configuration for Daemons ====

The concept of worker daemons can be implemented in two different ways. Either as a true daemon which would be an independent long running process that can be managed with [[http://supervisord.org/|Supervisor]], or as a script that's initiated by the HTTP server which most likely would be Apache.

In order to implement it in the second way, you'll need configure Apache to modify the ''php.ini'' settings so that the PHP script can be executed for a longer time. Apache by default closes the PHP execution if it runs for too long. The most flexible way of configuring Apache is through the ''.htaccess'' file. This can be done through [[http://davidwalsh.name/php-values-htaccess|setting PHP values]]. Another way is directly in the script through the [[http://davidwalsh.name/increase-php-script-execution-time-limit-ini_set|ini_set() function]].

Here's an example of different PHP settings set through the ''.htaccess''. Remember this will only apply to applications launched by the Apache HTTP server. If you want it to be a separate long running process, you'll need to use ''ini_set()'' for each individual process, but some of the ini settings wouldn't apply to a command line process.

<code>
#changes the maximum file size that can be uploaded
php_value upload_max_filesize 2M
#changes in seconds the length of execution
php_value max_execution_time 300
#the time in seconds of how long PHP is allowed to parse GET and POST data
php_value max_input_time 5
#the memory limit that PHP is allowed to occupy (takes up RAM), this can be for one script or the entire PHP application
php_value memory_limit 10M
#the maximum filesize that the POST payload can occupy
php_value post_max_size 2M
</code>

You can also investigate more [[http://www.php.net/manual/en/info.configuration.php|configuration settings in the PHP documentation]].
===== Sockets & RTC =====

You've heard of the real time web right? The rise of single page applications? Well these rely on web sockets and occasionally RTC. Before you go ahead with this, you need to understand network programming, the underlying protocols that the internet is built upon. [[http://gafferongames.com/networking-for-game-programmers/|Glenn Fiedler has provided an excellent series of blogs articles talking about network programming geared towards game developers]]. Read that before you proceed.

PHP has one good server side web socket implementation:

  * [[http://socketo.me/|Ratchet]] - Ratchet is a library/framework for asynchronous event based socket programming. This will allow you to create chat servers and other real time updates via socket push. It runs as a daemon similar to Gearman. Well specifically the framework is not a daemon, but any class leveraging Ratchet would be the daemon. This daemon would operate separately from your main solution stack. So make sure to architect it properly. Since it will be on different port to your main HTTP server, you'll need to place a [[http://haproxy.1wt.eu/|HAProxy]] in front of both Ratchet and Apache. Then you'll use ZMQ or Gearman to pass messages between your main application and your socket server.

There will be no free web hosts that will support a Ratchet configuration, you'll need to purchase a VPS or dedicated host to run this. Another option would be to use the third party service [[http://pusher.com/|Pusher]] as your intermediate socket server.

[[http://www.scriptol.com/ajax/webrtc.php|Web RTC]] is a very new technology, so [[https://labs.ericsson.com/blog/a-web-rtc-tutorial|there aren't many applications of this technology]]. You can however use the third party API [[http://www.tokbox.com/|TokBox]] for WebRTC video.